{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp tutorial.concise_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tutorial.concise_code\n",
    "> A concise version of the code used in [tutorial.walkthrough](tutorial.walkthrough.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import platform\n",
    "import warnings\n",
    "\n",
    "from huggingface_hub import from_pretrained_fastai\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoModelForTokenClassification, AutoTokenizer, pipeline\n",
    "\n",
    "from trouver.helper.arxiv import arxiv_id, arxiv_search, download_from_results, extract_last_names\n",
    "from trouver.helper.files_and_folders import get_download_path, get_huggingface_cache_dir, text_from_file\n",
    "from trouver.latex import find_main_latex_file\n",
    "from trouver.latex.convert import (\n",
    "    divide_preamble, divide_latex_text, custom_commands,\n",
    "    setup_reference_from_latex_parts\n",
    ")\n",
    "from trouver.latex.preamble import replace_inclusion_of_style_file_with_code\n",
    "from trouver.markdown.file import MarkdownFile\n",
    "from trouver.machine_learning.information_note_types import automatically_add_note_type_tags\n",
    "from trouver.machine_learning.tokenize.def_and_notat_token_classification import auto_mark_def_and_notats\n",
    "from trouver.machine_learning.definition_and_notation_naming import add_names_to_html_tags_in_info_note\n",
    "from trouver.machine_learning.notation_summarization import append_summary_to_notation_note\n",
    "from trouver.personal_vault.notes import notes_linked_in_notes_linked_in_note, notes_linked_in_note\n",
    "from trouver.notation.management import make_notation_notes_from_double_asts, make_notation_notes_from_HTML_tags\n",
    "from trouver.notation.in_standard_info_note import notation_notes_linked_in_see_also_section\n",
    "from trouver.obsidian.vault import VaultNote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download arXiv source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyunj\\Downloads\\kim_park_gm1dcmbmc\n",
      "C:\\Users\\hyunj\\Downloads\\kim_park_gm1dcmbmc\\main.tex\n"
     ]
    }
   ],
   "source": [
    "#| notest\n",
    "url = \"https://arxiv.org/abs/2106.10586\" # Replace this with the url \n",
    "results = list(arxiv_search(arxiv_id(url)))\n",
    "latex_dir = Path(get_download_path()) # Replace this with the path that you can to download the source file in; e.g. r'C:\\Users\\<your user name>' or r'/home/usr'\n",
    "\n",
    "downloaded_path = download_from_results(results, latex_dir, source=True)[0]\n",
    "print(downloaded_path)\n",
    "reference = downloaded_path.name\n",
    "author_full_names = [author.name for author in results[0].authors]\n",
    "author_names = extract_last_names(author_full_names)\n",
    "\n",
    "latex_file = find_main_latex_file(downloaded_path)\n",
    "print(latex_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide arXiv source document into parts for an Obsidian.md (sub)vault."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| notest\n",
    "# Change this as desired.\n",
    "# The name of the reference as well as the name of the folder that contains\n",
    "# the latex file\n",
    "reference = reference\n",
    "# Change this as desired.\n",
    "latex_file = latex_file \n",
    "# latex_file = Path(r'C:\\Users\\<user>') / reference / 'main.tex'\n",
    "latex_text = text_from_file(latex_file)\n",
    "preamble, _ = divide_preamble(latex_text)\n",
    "preamble = replace_inclusion_of_style_file_with_code(preamble, latex_dir)\n",
    "parts = divide_latex_text(latex_text, downloaded_path)\n",
    "cust_comms = custom_commands(preamble)\n",
    "# Replace the below as needed;\n",
    "# The path to the Obsidian vault in which to setup the \"subvault\"\n",
    "# For convenience, we currently set this as the folder where the\n",
    "# arXiv source file got downloaded into,\n",
    "# But you may change this to wherever your Obsiidan.md vault\n",
    "# actually is located at.\n",
    "vault = Path(downloaded_path)\n",
    "# Replace the below as needed;\n",
    "# The path relative to the vault of the directory in which to make\n",
    "# the new folder containing the new notes.\n",
    "location = Path('.')  \n",
    "# Replace the below as needed\n",
    "# The (family) names of the authors;\n",
    "author_names = author_names \n",
    "\n",
    "setup_reference_from_latex_parts(\n",
    "    parts, cust_comms, vault, location,\n",
    "    reference,\n",
    "    author_names,\n",
    "    # You may set this to `True` if you set up a `_references` folder\n",
    "    # in your Obsidian.md vault.\n",
    "    create_reference_file_in_references_folder=False,\n",
    "    # You may set this to `True` if you set up a `_templates` folder\n",
    "    # in your Obsidian.md vault.\n",
    "    create_template_file_in_templates_folder=False,\n",
    "    adjust_common_latex_syntax_to_markdown=True,\n",
    "    repeat_replacing_custom_commands=-1,\n",
    "    copy_obsidian_configs=None\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd3b843004d436ba0eae815756ea5ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "#| notest\n",
    "# Load the model that categorizes the type(s) of standard information notes\n",
    "repo_id = 'hyunjongkimmath/information_note_type'\n",
    "if platform.system() == 'Windows':\n",
    "    temp = pathlib.PosixPath # See https://stackoverflow.com/questions/57286486/i-cant-load-my-model-because-i-cant-put-a-posixpath\n",
    "    pathlib.PosixPath = pathlib.WindowsPath\n",
    "    information_note_type_model = from_pretrained_fastai(repo_id)\n",
    "    pathlib.PosixPath = temp\n",
    "else:\n",
    "    information_note_type_model = from_pretrained_fastai(repo_id)\n",
    "\n",
    "\n",
    "# Load the model the finds definitions and notations introduced in standard information notes\n",
    "model = AutoModelForTokenClassification.from_pretrained('hyunjongkimmath/def_and_notat_token_classification_model')\n",
    "tokenizer = AutoTokenizer.from_pretrained('hyunjongkimmath/def_and_notat_token_classification_model')\n",
    "def_notat_classifier = pipeline('ner', model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Load the models that names definitions and notations.\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('hyunjongkimmath/definition_naming_model')\n",
    "tokenizer = AutoTokenizer.from_pretrained('hyunjongkimmath/definition_naming_model')\n",
    "definition_naming_pipeline = pipeline('summarization', model=model, tokenizer=tokenizer)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('hyunjongkimmath/notation_naming_model')\n",
    "tokenizer = AutoTokenizer.from_pretrained('hyunjongkimmath/notation_naming_model')\n",
    "notation_naming_pipeline = pipeline('summarization', model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Load the model the summarizes what notations denote\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('hyunjongkimmath/notation_summarizations_model')\n",
    "tokenizer = AutoTokenizer.from_pretrained('hyunjongkimmath/notation_summarizations_model')\n",
    "summarizer = pipeline('summarization', model=model, tokenizer=tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make ML predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging note types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging notes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyunj\\Documents\\Development\\Python\\trouver\\trouver\\helper\\html.py:104: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  parsed_soup = BeautifulSoup(text, 'html.parser')\n"
     ]
    }
   ],
   "source": [
    "#| notest\n",
    "# Change `vault` and `reference` if necessary. These variables were defined in previous code.\n",
    "# vault = Path(r'C:\\Users\\<user>\\...')  # The path to the Obsidian vault\n",
    "# `reference` = 'kim_park_ga1dcmmc`\n",
    "index_note = VaultNote(vault, name=f'_index_{reference}')\n",
    "notes = notes_linked_in_notes_linked_in_note(index_note, as_dict=False)\n",
    "\n",
    "for note in notes:\n",
    "    if not note.exists():\n",
    "        raise Exception(note.name)\n",
    "\n",
    "print(\"Tagging notes\")\n",
    "automatically_add_note_type_tags(information_note_type_model, vault, notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locating definitions and notations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding notations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "#| notest\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "index_note = VaultNote(vault, name=f'_index_{reference}')\n",
    "notes = notes_linked_in_notes_linked_in_note(index_note, as_dict=False)\n",
    "\n",
    "for note in notes:\n",
    "    assert note.exists()\n",
    "\n",
    "print(\"Finding notations\")\n",
    "note_mfs = [MarkdownFile.from_vault_note(note) for note in notes]\n",
    "notation_notes = [\n",
    "    note for note, mf in zip(notes, note_mfs)\n",
    "    if mf.has_tag('_auto/_meta/definition') or mf.has_tag('_auto/_meta/notation')\n",
    "       or mf.has_tag('_meta/definition') or mf.has_tag('_meta/notation')]\n",
    "for note in notation_notes:\n",
    "    auto_mark_def_and_notats(note, def_notat_classifier, excessive_space_threshold=2)\n",
    "    # automatically_mark_notations(note, notation_identification_model, reference_name=reference)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naming definitions and notations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3296 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2587 > 512). Running this sequence through the model will result in indexing errors\n",
      "Your max_length is set to 200, but your input_length is only 132. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=66)\n",
      "Your max_length is set to 200, but your input_length is only 146. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=73)\n",
      "Your max_length is set to 200, but your input_length is only 92. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=46)\n",
      "Your max_length is set to 200, but your input_length is only 65. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=32)\n",
      "Your max_length is set to 200, but your input_length is only 51. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n",
      "Your max_length is set to 200, but your input_length is only 71. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=35)\n"
     ]
    }
   ],
   "source": [
    "#| notest\n",
    "index_note = VaultNote(vault, name=f'_index_{reference}')\n",
    "notes = notes_linked_in_notes_linked_in_note(index_note, as_dict=False)\n",
    "\n",
    "for note in notes:\n",
    "    try:\n",
    "        mf = MarkdownFile.from_vault_note(note)\n",
    "        add_names_to_html_tags_in_info_note(\n",
    "            note, def_pipeline=definition_naming_pipeline,\n",
    "            notat_pipeline=notation_naming_pipeline, overwrite=False) \n",
    "    except Exception as e:\n",
    "        print(f'{note.name} raised an exception')\n",
    "        print(e)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating notation notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| notest\n",
    "index_note = VaultNote(vault, name=f'_index_{reference}')\n",
    "notes = notes_linked_in_notes_linked_in_note(index_note, as_dict=False)\n",
    "\n",
    "for note in notes:\n",
    "    try:\n",
    "        new_notes = make_notation_notes_from_HTML_tags(note, vault, reference_name=reference)\n",
    "    except Exception as e:\n",
    "        print(note.name)\n",
    "        raise(e)\n",
    "    # assert len(new_notes) == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing notations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2511 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing notations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but your input_length is only 66. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=33)\n",
      "Your max_length is set to 200, but your input_length is only 193. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=96)\n",
      "Your max_length is set to 200, but your input_length is only 195. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=97)\n",
      "Your max_length is set to 200, but your input_length is only 195. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=97)\n"
     ]
    }
   ],
   "source": [
    "#| notest\n",
    "index_note = VaultNote(vault, name=f'_index_{reference}')\n",
    "notes = notes_linked_in_notes_linked_in_note(index_note, as_dict=False)\n",
    "\n",
    "for note in notes:\n",
    "    if not note.exists():\n",
    "        print(f\"note does not exist: {note.name}\")\n",
    "        raise Exception()\n",
    "\n",
    "print(\"Summarizing notations\")\n",
    "for note in notes:\n",
    "    notation_notes_linked_in_note = notation_notes_linked_in_see_also_section(note, vault)\n",
    "    for notation_note in notation_notes_linked_in_note:\n",
    "        append_summary_to_notation_note(notation_note, vault, summarizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
