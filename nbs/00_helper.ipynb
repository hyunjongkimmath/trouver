{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper\n",
    "\n",
    "> Helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp helper.__init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "import random\n",
    "from typing import Callable, Hashable, TypeVar\n",
    "from itertools import zip_longest\n",
    "import string\n",
    "\n",
    "import Levenshtein\n",
    "from Levenshtein import distance\n",
    "from thefuzz import fuzz\n",
    "import fuzzywuzzy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def substring_generator(input_string: str):\n",
    "    length = len(input_string)\n",
    "    for i in range(length):\n",
    "        for j in range(i + 1, length + 1):\n",
    "            yield input_string[i:j]\n",
    "\n",
    "\n",
    "def sublist_generator(input_list: list):\n",
    "    length = len(input_list)\n",
    "    for i in range(length):\n",
    "        for j in range(i + 1, length + 1):\n",
    "            yield input_list[i:j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_punctuation(\n",
    "        char: str # A str of length 1\n",
    "        ):\n",
    "    return char in '.!?,:;'\n",
    "\n",
    "def is_not_space_and_not_punc(\n",
    "        char: str # A str of length 1\n",
    "        ):\n",
    "    return not is_punctuation(char) and not char.isspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_punctuation('.')\n",
    "assert not is_punctuation('1')\n",
    "assert not is_not_space_and_not_punc('.')\n",
    "assert is_not_space_and_not_punc('a')\n",
    "assert not is_not_space_and_not_punc(' ')\n",
    "assert not is_not_space_and_not_punc('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def split_string_at_indices(s: str, indices: list[int]) -> list[str]:\n",
    "    return [s[i:j] for i, j in zip([0] + indices, indices + [None])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ' World!', ' How', ' are you?']\n"
     ]
    }
   ],
   "source": [
    "s = \"Hello World! How are you?\"\n",
    "indices = [5, 12, 16]\n",
    "result = split_string_at_indices(s, indices)\n",
    "print(result)\n",
    "test_eq(result, ['Hello', ' World!', ' How', ' are you?'])\n",
    "# Output: ['Hello', ' World!', ' How', ' are you?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Hello', ' World!', ' How', ' are you?']\n"
     ]
    }
   ],
   "source": [
    "s = \"Hello World! How are you?\"\n",
    "indices = [0, 5, 12, 16]\n",
    "result = split_string_at_indices(s, indices)\n",
    "print(result)\n",
    "test_eq(result, ['', 'Hello', ' World!', ' How', ' are you?'])\n",
    "# Output: ['Hello', ' World!', ' How', ' are you?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split list into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def split_list_into_chunks(original_list, split_ratio=0.75):\n",
    "    total_length = len(original_list)\n",
    "    target_length = int(total_length * split_ratio)\n",
    "    \n",
    "    chunks = []\n",
    "    current_index = 0\n",
    "    \n",
    "    while current_index < total_length:\n",
    "        chunk_size = random.randint(1, min(5, total_length - current_index))\n",
    "        chunks.append(original_list[current_index:current_index + chunk_size])\n",
    "        current_index += chunk_size\n",
    "    \n",
    "    random.shuffle(chunks)\n",
    "    \n",
    "    list1, list2 = [], []\n",
    "    current_length = 0\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        if current_length + len(chunk) <= target_length:\n",
    "            list1.extend(chunk)\n",
    "            current_length += len(chunk)\n",
    "        else:\n",
    "            list2.extend(chunk)\n",
    "    \n",
    "    return list1, list2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original list length: 100\n",
      "75% list length: 74\n",
      "25% list length: 26\n"
     ]
    }
   ],
   "source": [
    "original_list = list(range(100))\n",
    "list_75, list_25 = split_list_into_chunks(original_list)\n",
    "\n",
    "print(f\"Original list length: {len(original_list)}\")\n",
    "print(f\"75% list length: {len(list_75)}\")\n",
    "print(f\"25% list length: {len(list_25)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get top counted items in a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "K = TypeVar('K', bound=Hashable)  # Generic type for keys\n",
    "\n",
    "def get_top_counted_items(\n",
    "        data: dict[K, int],\n",
    "        top_percentile: float = 0.10,\n",
    "        max_number: int = 5,\n",
    "    ) -> list[K]:\n",
    "        \"\"\"Returns top items from a dictionary where keys are of type K and values are counts.\n",
    "        \n",
    "        Args:\n",
    "            data: Dictionary with keys of type K and integer counts as values\n",
    "            top_percentile: Percentage of top items to return (default: 0.10)\n",
    "            max_number: Maximum number of items to return (default: 5)\n",
    "            \n",
    "        Returns:\n",
    "            List of keys with the highest counts, maintaining the original key type\n",
    "        \"\"\"\n",
    "        sorted_items = sorted(data.items(), key=lambda x: x[1], reverse=True)\n",
    "        num_items = max(1, min(int(len(data) * top_percentile), max_number))\n",
    "        return [item[0] for item in sorted_items[:num_items]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test, test_eq\n",
    "from typing import Dict, List, TypeVar\n",
    "from collections.abc import Hashable\n",
    "\n",
    "K = TypeVar('K', bound=Hashable)\n",
    "\n",
    "def get_top_counted_items(\n",
    "    data: Dict[K, int],\n",
    "    top_percentile: float = 0.10,\n",
    "    max_number: int = 5,\n",
    ") -> List[K]:\n",
    "    sorted_items = sorted(data.items(), key=lambda x: x[1], reverse=True)\n",
    "    num_items = max(1, min(int(len(data) * top_percentile), max_number))\n",
    "    return [item[0] for item in sorted_items[:num_items]]\n",
    "\n",
    "# --- Tests ---\n",
    "# Test 1: Default behavior (10% with max 5)\n",
    "test_eq(\n",
    "    get_top_counted_items({'a':5, 'b':3, 'c':10}),\n",
    "    ['c']  # 3*0.10=0.3 → returns top 1\n",
    ")\n",
    "\n",
    "# Test 2: max_number override\n",
    "test_eq(\n",
    "    get_top_counted_items({1:100, 2:90, 3:80, 4:70}, top_percentile=1.0, max_number=2),\n",
    "    [1, 2]\n",
    ")\n",
    "\n",
    "# Test 3: top_percentile override\n",
    "test_eq(\n",
    "    get_top_counted_items({'x':1, 'y':2, 'z':3}, top_percentile=0.67),\n",
    "    ['z', 'y']  # 3*0.67=2.01 → returns top 2\n",
    ")\n",
    "\n",
    "# Test 4: Edge case - empty dict\n",
    "test_eq(get_top_counted_items({}), [])\n",
    "\n",
    "# Test 5: Edge case - single item\n",
    "test_eq(get_top_counted_items({'x':1}), ['x'])\n",
    "\n",
    "# Test 6: Hashable non-string keys\n",
    "class City:\n",
    "    def __init__(self, name): self.name = name\n",
    "    def __hash__(self): return hash(self.name)\n",
    "    \n",
    "nyc, london = City('NYC'), City('London')\n",
    "test_eq(\n",
    "    get_top_counted_items({nyc:8, london:12}),\n",
    "    [london]\n",
    ")\n",
    "\n",
    "# Test 7: Tuple keys (hashable)\n",
    "test_eq(\n",
    "    get_top_counted_items({(1,2):10, (3,4):5}),\n",
    "    [(1,2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whether one string is contained in another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# def char_substitution_cost(c1: str, c2: str) -> float:\n",
    "#     if c1 == c2 or c1 is None or c2 is None:\n",
    "#         return 0\n",
    "    \n",
    "#     if c1 not in string.ascii_letters or c2 not in string.ascii_letters:\n",
    "#         return 1.0\n",
    "    \n",
    "#     c1, c2 = c1.lower(), c2.lower()\n",
    "#     letter_dist = abs(ord(c1) - ord(c2)) / 25\n",
    "#     return min(letter_dist * 0.8, 0.8)\n",
    "\n",
    "def char_substitution_cost(c1: str, c2: str) -> float:\n",
    "    if c1 == c2 or c1 is None or c2 is None:\n",
    "        return 0\n",
    "    \n",
    "    if c1 not in string.ascii_letters or c2 not in string.ascii_letters:\n",
    "        return 1.0\n",
    "    \n",
    "    c1, c2 = c1.lower(), c2.lower()\n",
    "    letter_dist = abs(ord(c1) - ord(c2))\n",
    "    \n",
    "    # Non-linear penalty curve\n",
    "    if letter_dist <= 5:\n",
    "        return (letter_dist / 5) * 0.5  # 0-0.5 penalty for 0-5 distance\n",
    "    else:\n",
    "        return min(0.5 + (letter_dist - 5)/20, 0.8)  # 0.5-0.8 penalty for >5 distance\n",
    "\n",
    "def partial_ratio_with_alphabet(s1: str, s2: str) -> float:\n",
    "    \"\"\"Alphabet-aware partial ratio implementation.\"\"\"\n",
    "    if not s1 or not s2:\n",
    "        return 0.0  # or 100.0 if you consider empty strings a perfect match\n",
    "    # Ensure s1 is the shorter string\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "    \n",
    "    len1, len2 = len(s1), len(s2)\n",
    "    best_score = 0\n",
    "    \n",
    "    # Slide shorter string over longer string\n",
    "    for i in range(len2 - len1 + 1):\n",
    "        substring = s2[i:i+len1]\n",
    "        \n",
    "        # Calculate custom Levenshtein distance\n",
    "        d = [[0] * (len1 + 1) for _ in range(2)]\n",
    "        for j in range(len1 + 1):\n",
    "            d[0][j] = j\n",
    "            \n",
    "        for j in range(1, len1 + 1):\n",
    "            current_char = substring[j-1]\n",
    "            d[1][0] = j\n",
    "            \n",
    "            for k in range(1, len1 + 1):\n",
    "                cost = char_substitution_cost(s1[k-1], current_char)\n",
    "                d[1][k] = min(\n",
    "                    d[0][k] + 1,       # deletion\n",
    "                    d[1][k-1] + 1,     # insertion\n",
    "                    d[0][k-1] + cost   # substitution\n",
    "                )\n",
    "            \n",
    "            # Swap rows for memory efficiency\n",
    "            d[0], d[1] = d[1], d[0]\n",
    "        \n",
    "        raw_distance = d[0][len1]\n",
    "        similarity = 1 - (raw_distance / len1)\n",
    "        best_score = max(best_score, similarity)\n",
    "    \n",
    "    return best_score * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.66666666666667\n",
      "84.0\n",
      "96.66666666666667\n",
      "90.0\n"
     ]
    }
   ],
   "source": [
    "# Test Cases\n",
    "print(partial_ratio_with_alphabet(\"T M\", \"X: N → T N\"))  # ~85-92\n",
    "print(partial_ratio_with_alphabet(\"p → q\", \"p → d\"))     # ~75-85\n",
    "print(partial_ratio_with_alphabet(\"ABC\", \"ABD\"))         # ~80-90\n",
    "print(partial_ratio_with_alphabet(\"M\", \"N\"))             # ~92-96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def latex_str_in_latex_str_fuzz_metric(\n",
    "    substring_candidate: str,\n",
    "    superstring_candidate: str\n",
    ") -> float:\n",
    "    \"\"\"Fuzzy containment metric without length checks.\"\"\"\n",
    "    \n",
    "    # Calculate components\n",
    "    partial_sim_fuzz = fuzz.partial_ratio(substring_candidate, superstring_candidate) / 100\n",
    "    partial_sim_math = partial_ratio_with_alphabet(substring_candidate, superstring_candidate) / 100\n",
    "    \n",
    "    # Add containment penalty factor\n",
    "    containment_penalty = (\n",
    "        1.0 if len(substring_candidate) <= len(superstring_candidate)\n",
    "        else (len(superstring_candidate) / len(substring_candidate)) ** 2  # Quadratic penalty\n",
    "    )\n",
    "    \n",
    "    # Combined score with dynamic weighting\n",
    "    combined_score = 0.2 * partial_sim_fuzz + 0.8 * partial_sim_math\n",
    "    \n",
    "    # Apply fuzzy containment logic\n",
    "    return combined_score * containment_penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027777777777777776\n"
     ]
    }
   ],
   "source": [
    "short_str = r\"\\dim M\"\n",
    "long_str = r\"M\"\n",
    "print(latex_str_in_latex_str_fuzz_metric(short_str, long_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\dim M M\n",
      "0.027777777777777776\n",
      "\\dim M X: M \\rightarrow T M\n",
      "0.4726666666666667\n",
      "\\dim M \\left(U,\\left(x^{i}\\right)\\right)\n",
      "0.44066666666666665\n",
      "\\dim M M\n",
      "0.027777777777777776\n",
      "\\dim M X\n",
      "0.004444444444444444\n",
      "\\dim M U\n",
      "0.007777777777777777\n",
      "\\dim M \\left(x^{i}, v^{i}\\right)\n",
      "0.4726666666666667\n",
      "\\dim M \\pi^{-1}(U) \\subseteq T M\n",
      "0.4393333333333333\n",
      "\\dim M \\left(U,\\left(x^{i}\\right)\\right)\n",
      "0.44066666666666665\n",
      "\\dim M X: M \\rightarrow T M\n",
      "0.4726666666666667\n",
      "\\dim M U\n",
      "0.007777777777777777\n",
      "\\dim M \\hat{X}(x)=\\left(x^{1}, \\ldots, x^{n}, X^{1}(x), \\ldots, X^{n}(x)\\right)\n",
      "0.4793333333333335\n",
      "\\dim M X^{i}\n",
      "0.0944444444444444\n",
      "\\dim M i\n",
      "0.027777777777777776\n",
      "\\dim M X\n",
      "0.004444444444444444\n",
      "\\dim M x^{i}\n",
      "0.0944444444444444\n",
      "\\dim M X\n",
      "0.004444444444444444\n",
      "\\dim M U\n",
      "0.007777777777777777\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "test_superstring_candidates = ['M', 'X: M \\\\rightarrow T M', '\\\\left(U,\\\\left(x^{i}\\\\right)\\\\right)', 'M', 'X', 'U', '\\\\left(x^{i}, v^{i}\\\\right)', '\\\\pi^{-1}(U) \\\\subseteq T M', '\\\\left(U,\\\\left(x^{i}\\\\right)\\\\right)', 'X: M \\\\rightarrow T M', 'U', '\\\\hat{X}(x)=\\\\left(x^{1}, \\\\ldots, x^{n}, X^{1}(x), \\\\ldots, X^{n}(x)\\\\right)', 'X^{i}', 'i', 'X', 'x^{i}', 'X', 'U']\n",
    "\n",
    "test_substring_candidates = [r'\\dim M']\n",
    "\n",
    "for substring_candidate in test_substring_candidates:\n",
    "    for superstring_candidate in test_superstring_candidates:\n",
    "        print(substring_candidate, superstring_candidate)\n",
    "        print(latex_str_in_latex_str_fuzz_metric(substring_candidate, superstring_candidate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.22\n",
      "0.9073333333333334\n",
      "0.8746153846153847\n",
      "0.451\n",
      "0.25866666666666666\n",
      "0.4060000000000001\n"
     ]
    }
   ],
   "source": [
    "short_str = r\"\\mathcal{O}_X\"\n",
    "long_str = r\"H_{\\mathcal{O}_X}\"\n",
    "print(latex_str_in_latex_str_fuzz_metric(short_str, long_str))\n",
    "\n",
    "short_str = r\"(U, (x_i))\"\n",
    "long_str = r\"X: N \\rightarrow T N\"\n",
    "print(latex_str_in_latex_str_fuzz_metric(short_str, long_str))\n",
    "\n",
    "short_str = r\"T M\"\n",
    "long_str = r\"X: N \\rightarrow T N\"\n",
    "print(latex_str_in_latex_str_fuzz_metric(short_str, long_str))\n",
    "\n",
    "short_str = r\"\\mathcal{O}_X\"\n",
    "long_str = r\"\\mathscr{O}_X\"\n",
    "print(latex_str_in_latex_str_fuzz_metric(short_str, long_str))\n",
    "\n",
    "short_str = r\"\\Omega_X\"\n",
    "long_str = r\"\\mathscr{O}_X\"\n",
    "print(latex_str_in_latex_str_fuzz_metric(short_str, long_str))\n",
    "\n",
    "short_str = r\"F_{1}^\\times\\cdots\\times\"\n",
    "long_str = r\"\\left(x^{i}, v^{i}\\right)\"\n",
    "print(latex_str_in_latex_str_fuzz_metric(short_str, long_str))\n",
    "\n",
    "short_str = r\"T^{*} M\"\n",
    "long_str = r\"X: M \\rightarrow T M\"\n",
    "print(latex_str_in_latex_str_fuzz_metric(short_str, long_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44000000000000006"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def latex_str_is_likely_in_latex_str(\n",
    "        substring_candidate: str, #  \n",
    "        superstring_candidate: str,\n",
    "        metric: Callable[[str, str], float] = latex_str_in_latex_str_fuzz_metric,\n",
    "        threshold: float = 0.8, # The metric needs to achieve at least this threshold for `substring candidate` to be considered to be in `superstring_candidate`.\n",
    "        ) -> bool:\n",
    "    score = metric(substring_candidate, superstring_candidate)\n",
    "    return score > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_str = r\"\\mathcal{O}_X\"\n",
    "long_str = r\"\\Omega_{X}\"\n",
    "latex_str_is_likely_in_latex_str(short_str, long_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trouver_py312_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
