{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# latex.convert\n",
    "\n",
    "> Convert LaTeX files into Obsidian.md notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module contains functions and methods to automatically make Obsidian notes from LaTeX files of mathematical papers, most notably those on arXiv.\n",
    "\n",
    "See the [Potential Problems](#potential-problems) section below for some common errors that arise from this module and how to circumvent them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp latex.convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "from os import PathLike\n",
    "from pathlib import Path\n",
    "import re\n",
    "from typing import Union\n",
    "\n",
    "from pylatexenc import latexwalker, latex2text\n",
    "from pylatexenc.latexwalker import (\n",
    "    LatexWalker, LatexEnvironmentNode, get_default_latex_context_db,\n",
    "    LatexNode, LatexSpecialsNode, LatexMathNode, LatexMacroNode, LatexCharsNode,\n",
    "    LatexGroupNode, LatexCommentNode\n",
    ")\n",
    "from pylatexenc.latex2text import (\n",
    "    MacroTextSpec, EnvironmentTextSpec)\n",
    "from pylatexenc.macrospec import (\n",
    "    MacroSpec, LatexContextDb, EnvironmentSpec\n",
    ")\n",
    "import regex\n",
    "\n",
    "from trouver.helper import (\n",
    "    find_regex_in_text, dict_with_keys_topologically_sorted,\n",
    "    containing_string_priority, replace_string_by_indices, text_from_file\n",
    ")\n",
    "from trouver.markdown.markdown.file import (\n",
    "    MarkdownFile, MarkdownLineEnum\n",
    ")\n",
    "\n",
    "from trouver.markdown.obsidian.vault import VaultNote\n",
    "from trouver.markdown.obsidian.personal.index_notes import (\n",
    "    correspond_headings_with_folder, convert_title_to_folder_name\n",
    ")\n",
    "from trouver.markdown.obsidian.personal.reference import setup_folder_for_new_reference\n",
    "from trouver.markdown.obsidian.vault import VaultNote\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "DEFAULT_NUMBERED_ENVIRONMENTS = ['theorem', 'corollary', 'lemma', 'proposition',\n",
    "                                 'definition', 'conjecture', 'remark', 'example',\n",
    "                                 'question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import ExceptionExpected, test_eq\n",
    "from trouver.helper import _test_directory, non_utf8_chars_in_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are some frequently problems that arise when using this module:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UnicodeDecodeErrors arise when reading LaTeX files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the `text_from_file` method in `trouver.helper` reads files and attempts to decode them in `utf-8`. If a LaTeX file has characters that cannot be decoded into `utf-8`, then a `UnicodeDecodeError` may be raised. In this case, one can find identify these characters using the `trouver.helper.non_utf8_chars_in_file` method and modify the LaTeX file manually. It may be useful to use a text editor to jump to the positions that the characters are at and to change the encoding of the LaTeX file into `utf-8`; for example, the author of `trouver` has opened some `ANSI`-encoded LaTeX documents in `Notepad++` and converted their encoding into `UTF-8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are the non unicode characters and their positions: [('Ê', 130), ('Ê', 165), ('Ë', 196), ('Ì', 227)]\n"
     ]
    }
   ],
   "source": [
    "latex_file_path = _test_directory() / 'latex_examples' / 'circumflex_E_example.tex'\n",
    "contents, non_utf8_chars = non_utf8_chars_in_file(latex_file_path)\n",
    "#print(contents.decode(encoding='utf-8'))\n",
    "test_eq(len(non_utf8_chars), 4)\n",
    "print(f'The following are the non unicode characters and their positions: {non_utf8_chars}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `NoDocumentNodeErrors` arise even though the LaTeX file has a document environemt (i.e. `\\begin{document}...\\end{document}`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `find_document_node` method in this module sometimes is not able to detect the docment environment of a LaTeX file. This error is known to arise when\n",
    "- there are macros (which include commands) defined that represents/expands to characters including `\\begin{...}... \\end{...}`. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO in the above explanation, include an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LaTeX comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def remove_comments(text: str) -> str:\n",
    "    # Find all occurrences of the comment pattern %[^\\n]*\n",
    "    return re.sub(r\"%[^\\n]*\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\newcommand{\\field}[1]{\\mathbb{#1}}\n",
      "\\newcommand{\\mat}[4]{\\left[\\begin{array}{cc}#1 & #2 \\\\\n",
      "                                         #3 & #4\\end{array}\\right]}\n",
      "\\newcommand{\\dual}[1]{#1^{\\vee}}\n",
      "\\newcommand{\\compl}[1]{\\hat{#1}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = r\"\"\"% Commands with parameters\n",
    "\\newcommand{\\field}[1]{\\mathbb{#1}}\n",
    "\\newcommand{\\mat}[4]{\\left[\\begin{array}{cc}#1 & #2 \\\\\n",
    "                                         #3 & #4\\end{array}\\right]}\n",
    "\\newcommand{\\dual}[1]{#1^{\\vee}}\n",
    "\\newcommand{\\compl}[1]{\\hat{#1}}\n",
    "\"\"\"\n",
    "assert '%' not in remove_comments(text)\n",
    "print(remove_comments(text))\n",
    "\n",
    "text = r\"\"\"Hi. I'm not commented. %But I am!\"\"\"\n",
    "test_eq(remove_comments(text), \"Hi. I'm not commented. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide LaTeX file into parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make Obsidian notes from a LaTeX file, I use sections/subsections, and environments as places to make new notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to think about:\n",
    "Sections/subsections\n",
    "environments, including theorems, corollaries, propositions, lemmas, definitions, notations\n",
    "citations\n",
    "Macros defined in the preamble?\n",
    "\n",
    "LatexMacroNodes include: sections/subsections, citations, references, and labels, e.g.\n",
    "\n",
    "```latex\n",
    "> \\section{Introduction}\n",
    "\\cite{ellenberg2nilpotent}\n",
    "\\subsection{The section conjecture}\n",
    "\\'e\n",
    "\\ref{fundamental-exact-sequence}\n",
    "\\cite{stix2010period}\n",
    "\\ref{fundamental-exact-sequence}\n",
    "\\cite{stix2012rational}\n",
    "\\cite[Appendix C]{stix2010period}\n",
    "\\subsection{The tropical section conjecture}\n",
    "\\label{subsec:tropical-section-conjecture}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide the preamble from the rest of the document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some macros and commands defined in the preamble seem to prevent the `pylatexenc` methods from properly identifying the document environment/node in a LaTeX document. To circumvent this, we define a function to divide the preamble from the rest of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def divide_preamble(\n",
    "        text: str, # LaTeX document\n",
    "        document_environment_name: str = \"document\"\n",
    "        ) -> tuple[str, str]:\n",
    "    \"\"\"Divide the preamble from the rest of a LaTeX document.\n",
    "    \"\"\"\n",
    "    begin_environment_str = rf'\\begin{{{document_environment_name}}}'\n",
    "    pattern = re.compile(re.escape(begin_environment_str))\n",
    "    match = re.search(pattern, text) \n",
    "    start_match, end_match = match.span()\n",
    "    return text[:start_match], text[start_match:]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_file_path = _test_directory() / 'latex_examples' / 'example_with_a_command_with_begin.tex'\n",
    "text = text_from_file(latex_file_path)\n",
    "\n",
    "preamble, document = divide_preamble(text)\n",
    "assert r'\\begin{displaymath}' in preamble\n",
    "assert r'Hyun Jong Kim' in preamble\n",
    "\n",
    "assert r'Hyun Jong Kim' not in document\n",
    "assert document.startswith(r'\\begin{document}')\n",
    "assert document.endswith('\\\\end{document}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Document Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NoDocumentNodeError(Exception):\n",
    "    \"\"\"Exception raised when a LatexEnvironmentNode corresponding to the document \n",
    "    environment is expected in a LaTeX string, but no such node exists.\n",
    "    \n",
    "    **Attributes**\n",
    "    - text - str\n",
    "        - The text in which the document environment is not found.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        super().__init__(\n",
    "            f\"The following text does not contain a document environment:\\n{text}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def find_document_node(\n",
    "        text: str, # LaTeX str\n",
    "        document_environment_name: str = \"document\" # The name of the document environment.\n",
    "        ) -> LatexEnvironmentNode:\n",
    "    \"\"\"Find the `LatexNode` object for the main document in `text`.\n",
    "    \n",
    "    **Raises**\n",
    "    - NoDocumentNodeError\n",
    "        - If document environment node is not detected.\n",
    "    \"\"\"\n",
    "    w = LatexWalker(text)\n",
    "    nodelist, _, _ = w.get_latex_nodes(pos=0)\n",
    "    for node in nodelist:\n",
    "        if node.isNodeType(LatexEnvironmentNode)\\\n",
    "                and node.environmentname == document_environment_name:\n",
    "            return node\n",
    "    raise NoDocumentNodeError(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main content of virtually all LaTeX math articles belongs to a document environment, which pylatexenc can often detect. The `find_document_node` function returns this `LatexEnvironmentNode` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_file_path = _test_directory() / 'latex_examples' / 'latex_example_1' / 'main.tex'\n",
    "text = text_from_file(latex_file_path)\n",
    "document_node = find_document_node(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the LaTeX file has no `document` environment, then a `NoDocumentNodeError` is raised:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This latex document has its `document` environment commented out.\n",
    "latex_file_path = _test_directory() / 'latex_examples' / 'latex_example_2' / 'main.tex'\n",
    "text = text_from_file(latex_file_path)\n",
    "with ExceptionExpected(NoDocumentNodeError):\n",
    "    document_node = find_document_node(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the time of this writinga `NoDocumentNodeError` may be raised even if the LaTeX file has a proper `document` environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_file_path = _test_directory() / 'latex_examples' / 'example_with_a_command_with_begin.tex'\n",
    "text = text_from_file(latex_file_path)\n",
    "\n",
    "# Perhaps in the future, pylatexenc will be able to find the document node for this file.\n",
    "# When that time comes, delete this example.\n",
    "with ExceptionExpected(NoDocumentNodeError):\n",
    "    find_document_node(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `divide_preamble` function can be used to circumvent this problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preamble, document = divide_preamble(text)\n",
    "document_node = find_document_node(document)\n",
    "test_eq(document_node.environmentname, 'document')\n",
    "assert document_node.isNodeType(LatexEnvironmentNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# Find no document node error causes\n",
    "\n",
    "# latex_file_path = r'_tests\\latex_full\\litt_cfag\\main.tex'\n",
    "# text = text_from_file(latex_file_path)\n",
    "# document_node = find_document_node(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect environment names used in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def environment_names_used(\n",
    "        text: str # LaTeX document\n",
    "        ) -> set[str]: # The set of all environment names used in the main document.\n",
    "    \"\"\"Return the set of all environment names used in the main document\n",
    "    of the latex code.\n",
    "    \"\"\"\n",
    "    document_node = find_document_node(text)\n",
    "    return {node.environmentname for node in document_node.nodelist\n",
    "            if node.isNodeType(LatexEnvironmentNode)}        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writers often use different environment names. For examples, writers often use `theorem`, `thm`, or `theo` for theorem environments or `lemma` or `lem` for lemma environments. The `environment_names_used` function returns the environment names actually used in the tex file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example below, note that only the environments that are actually used are returned. For instance, the preamble of the document defines the theorem environments `problem`, and `lemma` (among other things), but these are not actually used in the document itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_file_path = _test_directory() / 'latex_examples' / 'has_fully_written_out_environment_names.tex'\n",
    "sample_text_1 = text_from_file(latex_file_path)\n",
    "sample_output_1 = environment_names_used(sample_text_1)\n",
    "test_eq({'corollary', 'proof', 'maincorollary', 'abstract', 'proposition'}, sample_output_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document in the example below uses shorter names for theorem environments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_file_path = _test_directory() / 'latex_examples' / 'has_shorter_environment_names.tex'\n",
    "sample_text_2 = text_from_file(latex_file_path)\n",
    "sample_output_2 = environment_names_used(sample_text_2)\n",
    "test_eq({'conj', 'notation', 'corollary', 'defn'}, sample_output_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify the numbering convention of a LaTeX document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LaTeX documents have various number conventions. Here are some examples of papers on the arXiv and notes on their numbering schemes. Note that the source code to these articles are publicly available on the arXiv. \n",
    "\n",
    "- Ellenberg, Venkatesh, and Westerland, *[Homological stability for Hurwitz spaces and the Cohen-Lenstra conjecture over function fields](https://arxiv.org/abs/0912.0325)*, \n",
    "    - The subsections and theorem-like environments of each section share a numbering scheme, e.g. section 1 has subsection `1.1 The Cohen-Lenstra heuristics`, `1.2 Theorem`, `1.3 Hurwitz spaces`. This is accomplished by defining theorem-like environments using the `subsection` counter, e.g.\n",
    "\n",
    "        ```latex\n",
    "        \\theoremstyle{plain}\n",
    "        \\newtheorem{thm}[subsection]{Theorem}\n",
    "        \\newtheorem{prop}[subsection]{Proposition}\n",
    "        \\newtheorem{cor}[subsection]{Corollary}\n",
    "        \\newtheorem{remark}{Remark}\n",
    "        \\newtheorem{conj}[subsection]{Conjecture}\n",
    "        \\newtheorem*{conj*}{Conjecture}\n",
    "         ```\n",
    "\n",
    "        defines the `thm`, `prop`, `cor`, and `conj` environments to be numbered using the `subsection` counter, the `remark` environmment to be defiend as an unnumbered environment, and the `conj*` environment to be defined as an unnumbered environment with a different name than the `conj` environment.\n",
    "\n",
    "    - The `\\swapnumbers` command is included in the preamble to change the way that theorems are numbered in the document, e.g. the article has `1.2 Theorem` as opposed to `Theorem 1.2`.\n",
    "    - The equations are numbered along the subsections - this is accomplished by the lines \n",
    "\n",
    "        ```latex\n",
    "        \\numberwithin{equation}{subsection}\n",
    "        \\renewcommand{\\theequation}{\\thesubsection.\\arabic{equation}}\n",
    "        ```\n",
    "\n",
    "        in the preamble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: consider different \n",
    "# TODO: cosider swapnumbers\n",
    "# TODO: consider "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def counters_for_environments(\n",
    "        text: str # The LaTeX document\n",
    "        ) -> dict:  \n",
    "    r\"\"\"Return the dict specifying the counters for each theorem-like environment.\n",
    "\n",
    "    This function uses two separate regex patterns, one to detect the invocations of `\\newtheorem`\n",
    "    in which the optional parameter is the second parameter and one to detect those in which\n",
    "    the optional parameter is the third parameter.\n",
    "\n",
    "    Assumes that\n",
    "    - invocations of the `\\newtheorem` command are exclusively in the\n",
    "    preamble of the LaTeX document.\n",
    "    - theorem-like environments are defined using the `\\newtheorem` command.\n",
    "    - no environments of the same name are defined twice.\n",
    "\n",
    "    \"\"\"\n",
    "    preamble, _ = divide_preamble(text)\n",
    "    second_parameter_pattern = re.compile(\n",
    "        # r'\\\\newtheorem\\s*\\{\\s*(\\w+)\\s*\\}\\s*(\\[\\s*(\\w+)\\s*\\])?\\s*\\{\\s*(.*)\\s*\\}')\n",
    "        # In this case, the optional parameter (if any) should not follow the newtheorem.\n",
    "        r'\\\\newtheorem\\s*\\{\\s*(\\w+)\\s*\\}\\s*(\\[\\s*(\\w+)\\s*\\])?\\s*\\{\\s*(.*)\\s*\\}(?!\\s*\\[\\s*(\\w+)\\s*\\])')\n",
    "    third_parameter_pattern = re.compile(\n",
    "        r'\\\\newtheorem\\s*\\{\\s*(\\w+)\\s*\\}\\s*\\{\\s*(.*)\\s*\\}\\s*(\\[\\s*(\\w+)\\s*\\])?')\n",
    "    second_results = _search_counters_by_pattern(preamble, second_parameter_pattern, 3)\n",
    "    third_results = _search_counters_by_pattern(preamble, third_parameter_pattern, 4)\n",
    "    return second_results | third_results\n",
    "    \n",
    "\n",
    "def _search_counters_by_pattern(\n",
    "        preamble: str,\n",
    "        newtheorem_regex: re.Pattern,\n",
    "        counter_group: int # This depends on which `newtheorem_regex` is used, and is either 3 or 4. \n",
    "        ) -> dict:\n",
    "    \"\"\"\n",
    "    Capture the newly defined theorem-like environment names as well as the\n",
    "    counters that they belong to\"\"\"\n",
    "    counters = {}\n",
    "    for match in newtheorem_regex.finditer(preamble):\n",
    "        env_name = match.group(1)\n",
    "        counter = match.group(counter_group)\n",
    "        # If no counter was specified, use the environment name as the counter\n",
    "        if counter is None:\n",
    "            counter = env_name\n",
    "        counters[env_name] = counter\n",
    "    return counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text_from_file(_test_directory() / 'latex_examples' / 'newtheorem_example.tex') \n",
    "\n",
    "counters = counters_for_environments(text)\n",
    "test_eq(counters, {'theorem': 'theorem', 'lemma': 'theorem', 'definition': 'theorem', 'corollary': 'corollary', 'remark': 'theorem'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = r\"\"\"\n",
    "\\theoremstyle{plain}\n",
    "\\newtheorem{thm}[subsection]{Theorem}\n",
    "\\newtheorem{prop}[subsection]{Proposition}\n",
    "\\newtheorem{cor}[subsection]{Corollary}\n",
    "\\newtheorem{remark}{Remark}\n",
    "\\newtheorem{conj}[subsection]{Conjecture}\n",
    "\\newtheorem*{conj*}{Conjecture}\n",
    "\\begin{document}\n",
    "\\end{document}\n",
    "\"\"\"\n",
    "counters = counters_for_environments(text)\n",
    "test_eq(counters, {'thm': 'subsection', 'prop': 'subsection', 'cor': 'subsection', 'remark': 'remark', 'conj': 'subsection'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# Test that the contents of the `counters_for_environments` function are detecting\n",
    "# The defined commands correctly.\n",
    "text = text_from_file(_test_directory() / 'latex_examples' / 'newtheorem_example.tex') \n",
    "preamble, _ = divide_preamble(text)\n",
    "second_parameter_pattern = re.compile(\n",
    "    # r'\\\\newtheorem\\s*\\{\\s*(\\w+)\\s*\\}\\s*(\\[\\s*(\\w+)\\s*\\])?\\s*\\{\\s*(.*)\\s*\\}')\n",
    "    r'\\\\newtheorem\\s*\\{\\s*(\\w+)\\s*\\}\\s*(\\[\\s*(\\w+)\\s*\\])?\\s*\\{\\s*(.*)\\s*\\}(?!\\s*\\[\\s*(\\w+)\\s*\\])')\n",
    "third_parameter_pattern = re.compile(\n",
    "    r'\\\\newtheorem\\s*\\{\\s*(\\w+)\\s*\\}\\s*\\{\\s*(.*)\\s*\\}\\s*(\\[\\s*(\\w+)\\s*\\])?')\n",
    "second_results = _search_counters_by_pattern(preamble, second_parameter_pattern, 3)\n",
    "third_results = _search_counters_by_pattern(preamble, third_parameter_pattern, 4)\n",
    "assert 'remark' not in second_results\n",
    "assert 'remark' in third_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the display names of environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, `\\newtheorem{theorem}{Theorem}` defines a theorem-like environment called `theorem` whose display name is `Theorem`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def display_names_of_environments(\n",
    "        text: str # The LaTeX document\n",
    "        ) -> dict:  \n",
    "    r\"\"\"Return the dict specifying the display names for each theorem-like environment.\n",
    "\n",
    "    This function uses two separate regex patterns, one to detect the invocations of `\\newtheorem`\n",
    "    in which the optional parameter is the second parameter and one to detect those in which\n",
    "    the optional parameter is the third parameter.\n",
    "\n",
    "    Assumes that\n",
    "    - invocations of the `\\newtheorem` command are exclusively in the\n",
    "    preamble of the LaTeX document.\n",
    "    - theorem-like environments are defined using the `\\newtheorem` command.\n",
    "    - no environments of the same name are defined twice.\n",
    "\n",
    "    \"\"\"\n",
    "    preamble, _ = divide_preamble(text)\n",
    "    second_parameter_pattern = re.compile(\n",
    "        # In this case, the optional parameter (if any) should not follow the newtheorem.\n",
    "        r'\\\\newtheorem\\*?\\s*\\{\\s*(\\w+\\*?)\\s*\\}\\s*(\\[\\s*(\\w+)\\s*\\])?\\s*\\{\\s*(.*)\\s*\\}(?!\\s*\\[\\s*(\\w+)\\s*\\])')\n",
    "    third_parameter_pattern = re.compile(\n",
    "        r'\\\\newtheorem\\*?\\s*\\{\\s*(\\w+\\*?)\\s*\\}\\s*\\{\\s*(.*)\\s*\\}\\s*(\\[\\s*(\\w+)\\s*\\])?')\n",
    "    second_results = _search_display_names_by_pattern(preamble, second_parameter_pattern, 4)\n",
    "    third_results = _search_display_names_by_pattern(preamble, third_parameter_pattern, 2)\n",
    "    return second_results | third_results\n",
    "    \n",
    "\n",
    "def _search_display_names_by_pattern(\n",
    "        preamble: str,\n",
    "        newtheorem_regex: re.Pattern,\n",
    "        display_name_group: int # This depends on which `newtheorem_regex` is used, and is either 3 or 4. \n",
    "        ) -> dict:\n",
    "    \"\"\"\n",
    "    Capture the newly defined theorem-like environment names as well as the\n",
    "    counters that they belong to\"\"\"\n",
    "    display_names = {}\n",
    "    for match in newtheorem_regex.finditer(preamble):\n",
    "        env_name = match.group(1)\n",
    "        display_name = match.group(display_name_group)\n",
    "        display_names[env_name] = display_name\n",
    "    return display_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text_from_file(_test_directory() / 'latex_examples' / 'newtheorem_example.tex') \n",
    "display_names = display_names_of_environments(text)\n",
    "test_eq(display_names, {'theorem': 'Theorem',\n",
    " 'lemma': 'Lemma',\n",
    " 'definition': 'Definition',\n",
    " 'corollary': 'Corollary',\n",
    " 'conjecture*': 'Conjecture',\n",
    " 'remark': 'Remark'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide latex text into parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of different numbering conventions:\n",
    "# Ellenberg, Venkatesh, Westerland, HOmological stability - 1.1 The Cohen-Lenstra heuristics, 1.2 Theorem, 1.3 Hurwitz spaces, 1.4 Stability of homology, 1.5 Conjecture, 1.6 Some context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def divide_latex_text(\n",
    "        text: str, # The text of a LaTeX document\n",
    "        environments_to_divide_along: list[str], # A list of the names of environments that warrant a new note\n",
    "        numbered_environments: list[str], # A list of the names of environments that do not warrant a new note\n",
    "        numbering_convention: str,\n",
    "        section_name: str = 'section', # The command name for sections\n",
    "        subsection_name: str= 'subsection', # The command name for subsections\n",
    "        proof_name: str = 'proof', # The environment name for proofs\n",
    "        ) -> list[tuple[str, str]]: \n",
    "    \"\"\"Divide LaTeX text to convert into Obsidian.md notes.\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# TODO: numbering convention could be theorems separate (e.g. theorem 1, 2, ...)\n",
    "# and subsections separate.\n",
    "# TODO: fix up this method\n",
    "def divide_latex_text(\n",
    "        text, # The text of a latex document.\n",
    "        numbered_environments: list[str] = DEFAULT_NUMBERED_ENVIRONMENTS, # A list of the names of environments which are numbered in the latex code. \n",
    "        numbering_convention: str = 'separate', # One of <br><br> - 'separate': Subsections of a section have separate numberings, e.g. 'Lemma 1.2.1, Proposition 1.2.2, Figure 1.2.3, Theorem 1.3.1' <br> - 'shared': Subsections of a section share numberings, e.g.  'Lemma 1.1, Proposition 1.2, Figure 1.3, Theorem 1.4'\n",
    "        section_name: str = 'section', # The command name for sections. For example, SGA has chapters and sections. For the purposes of this function, it is appropriate to regard them as sections and subsections, respectively.\n",
    "        subsection_name: str = 'subsection', # The commmand name for subsections\n",
    "        proof_name: str = 'proof' # The environment name for proofs\n",
    "        ) -> list[tuple[str, str]]: # Each tuple corresponds to an Obsidian note to be constructed.  Such a tuple is of the form `[<node_type & numbering>, <text>]` where `node_type & numbering` is a string which serves as a title for the text making up the note, and `text` is the content of the note.\n",
    "    \"\"\"Divides latex text to convert into Obsidian notes.\n",
    "    \n",
    "    \"\"\"\n",
    "    document_node = find_document_node(text)\n",
    "    section_num = 0\n",
    "    subsection_num = 0\n",
    "    environment_num = 0\n",
    "    outside_num = 1  # Since not everything is in a nice environment, many \n",
    "                     # notes will need their own numbers.\n",
    "    parts = []\n",
    "    accumulation = ''\n",
    "    for node in document_node.nodelist:\n",
    "        (section_num, subsection_num, environment_num, outside_num,\n",
    "         accumulation)\\\n",
    "            = _process_node(\n",
    "                section_num, subsection_num, environment_num, outside_num,\n",
    "                accumulation, parts, node, section_name, subsection_name,\n",
    "                proof_name, numbered_environments, numbering_convention)\n",
    "            \n",
    "    outside_num += 1\n",
    "    parts.append([str(outside_num), accumulation])\n",
    "    return parts\n",
    "            \n",
    "def _process_node(\n",
    "        section_num: int, subsection_num: int, environment_num: int,\n",
    "        outside_num: int, accumulation: str, parts: list, node: LatexNode,\n",
    "        section_name: str, subsection_name: str, proof_name: str,\n",
    "        numbered_environments: list[str], numbering_convention: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Choose the node-processing method, if the node is a section/subsection or environment\n",
    "    and\n",
    "\n",
    "    \"\"\"\n",
    "    process_method_to_run = None\n",
    "    if node.isNodeType(LatexMacroNode) and node.macroname == section_name:\n",
    "        process_method_to_run = _process_section\n",
    "    elif node.isNodeType(LatexMacroNode) and node.macroname == subsection_name:\n",
    "        process_method_to_run = _process_subsection\n",
    "    elif (node.isNodeType(LatexEnvironmentNode)\n",
    "          and node.environmentname in numbered_environments):\n",
    "        process_method_to_run = _process_environment_node\n",
    "    if process_method_to_run:\n",
    "        (section_num, subsection_num, environment_num, outside_num,\n",
    "        accumulation)\\\n",
    "            = process_method_to_run(\n",
    "            section_num, subsection_num, environment_num, outside_num,\n",
    "            accumulation, parts, node, section_name, subsection_name,\n",
    "            numbering_convention)\n",
    "    elif (node.isNodeType(LatexEnvironmentNode)\n",
    "          and node.environmentname == proof_name):\n",
    "          # TODO: if the environment is a proof, and if it starts a section/subsection,\n",
    "          # Then the proof is appended into the title of the section/subsection, see\n",
    "          # landesman_litt_ipwc, around line 1858-1863 for example.\n",
    "        parts[-1][1] += f'\\n{node.latex_verbatim()}'\n",
    "    else:\n",
    "        accumulation += node.latex_verbatim()\n",
    "    return (section_num, subsection_num, environment_num, outside_num,\n",
    "            accumulation)\n",
    "\n",
    "\n",
    "def _process_section(\n",
    "        section_num: int, subsection_num: int, environment_num: int,\n",
    "        outside_num: int, accumulation: str, parts: list[list],\n",
    "        node: LatexMacroNode, section_name: str, subsection_name: str,\n",
    "        numbering_convention: str) -> tuple:\n",
    "    \"\"\"Do stuff when the node is a section node. Return updated\n",
    "    section_num, subsection_num, environment_num\n",
    "    \"\"\"\n",
    "    numbered, title  = _section_title(\n",
    "        node.latex_verbatim(), section_name, subsection_name)\n",
    "    section_num += 1 if numbered else 0\n",
    "    subsection_num = 0\n",
    "    environment_num = 0\n",
    "    if accumulation.strip() != '':\n",
    "        parts.append([str(outside_num), accumulation])\n",
    "        outside_num += 1\n",
    "        accumulation = ''\n",
    "    parts.append([f'{section_name} {section_num}', title])\n",
    "    return (section_num, subsection_num, environment_num, outside_num,\n",
    "            accumulation)\n",
    "    \n",
    "\n",
    "def _process_subsection(\n",
    "        section_num: int, subsection_num: int, environment_num: int,\n",
    "        outside_num: int, accumulation: str, parts: list[list],\n",
    "        node: LatexMacroNode, section_name: str, subsection_name: str,\n",
    "        numbering_convention: str) -> tuple:\n",
    "    \"\"\"Do stuff when the node is a subsection node.\n",
    "    \"\"\"\n",
    "    numbered, title  = _section_title(\n",
    "        node.latex_verbatim(), section_name, subsection_name)\n",
    "    subsection_num += 1 if numbered else 0\n",
    "    if numbering_convention == 'separate':\n",
    "        environment_num = 0\n",
    "    if accumulation.strip() != '':\n",
    "        parts.append([str(outside_num), accumulation])\n",
    "        outside_num += 1\n",
    "        accumulation = ''\n",
    "    parts.append([f'{subsection_name} {section_num}.{subsection_num}', title])\n",
    "    return (section_num, subsection_num, environment_num, outside_num,\n",
    "            accumulation)\n",
    "\n",
    "\n",
    "def _process_environment_node(\n",
    "        section_num: int, subsection_num: int, environment_num: int,\n",
    "        outside_num: int, accumulation: str, parts: list[list],\n",
    "        node: LatexMacroNode, section_name: str, subsection_name: str,\n",
    "        numbering_convention: str) -> tuple:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    environment_num += 1\n",
    "    if accumulation.strip() != '':\n",
    "        parts.append([str(outside_num), accumulation])\n",
    "        outside_num += 1\n",
    "        accumulation = ''\n",
    "    if numbering_convention == 'separate':\n",
    "        pointed_numbering = f'{section_num}.{subsection_num}.{environment_num}'\n",
    "        numbering = f'{node.environmentname} {pointed_numbering}'\n",
    "    elif numbering_convention == 'shared':\n",
    "        numbering = f'{node.environmentname} {section_num}.{environment_num}'\n",
    "    parts.append([numbering, node.latex_verbatim()])\n",
    "    return (section_num, subsection_num, environment_num, outside_num,\n",
    "            accumulation)\n",
    "\n",
    "\n",
    "def _section_title(text: str, section_name, subsection_name) -> str:\n",
    "    \"\"\"Returns the title of a section or subsection from a latex str\n",
    "    and whether or not the section/subsection is numbered.\n",
    "    \n",
    "    **Parameters**\n",
    "    - text - str\n",
    "    - section_name - str\n",
    "    - subsection_name - str\n",
    "    \n",
    "    **Returns**\n",
    "    - str, bool\n",
    "    \"\"\"\n",
    "    # TODO: test things like `\\\\section {Generating series of special divisors}`\n",
    "    # See qiu_amsd for example.\n",
    "    # TODO: deal with the possibility of multi-line sections/subsections,\n",
    "    # e.g. \\subsection{Arithmetic intersrection\\n pairing},\n",
    "    # see qiu_amsd for example\n",
    "    regex_search = re.search(r'\\\\' + fr'(?:{section_name}|{subsection_name}) *?'\n",
    "                             + r'(?:\\[.*\\])?(\\*)?\\{(.*)\\}', text)\n",
    "    # regex_search = re.search(r'\\\\' + fr'(?:{section_name}|{subsection_name})'\n",
    "    #                          + r'(?:\\[.*\\])?(\\*)?\\{(.*)\\}', text)\n",
    "    # print(text)\n",
    "    # print(section_name, subsection_name)\n",
    "    if regex_search is None:\n",
    "        print(text, section_name, subsection_name)\n",
    "    return not bool(regex_search.group(1)), regex_search.group(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `divide_latex_text` function divides latex text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latex_file_path = r'_tests\\latex_full\\pauli_wickelgren\\main.tex'\n",
    "# text = text_from_file(latex_file_path)\n",
    "# parts = divide_latex_text(text, numbering_convention='separate')\n",
    "# for title, text in parts[39:44]:\n",
    "#     print(title, text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find a list of environment names commonly used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: examples with different numbering convention and different numbered environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make numbering_convention work correctly.\n",
    "# Here are some latex files with different conventions:\n",
    "# - All subsections in a section share numbering, \n",
    "#   - achter_pries_imht https://arxiv.org/abs/math/0608038: e.g. Lemmas 2.1, 2.2, 2.3 are in subsection 2.2 and Lemma 2.4 and Remark 2.5 are in subsection 2.4.as_integer_ratio\n",
    "#   - pauli_wickelgren https://arxiv.org/abs/2010.09374: e.g. Example 3.5, 3.11 are in subsubsection 3.3.2, Exercise 4.1, Remark 4.2, are in subsection 4.1, Theorem 4.3 is in subsection 4.2, Theorem 4.4 is in subsection 4.3\n",
    "# - Different environment types have different counts and the counts do not show the section number.\n",
    "#   - vankataramana_imbrd https://arxiv.org/abs/1205.6543: \n",
    "#       - e.g. section 1 has Theorem 1, Remark 1, Remark 2, Remark 3, subsection 1.1.3 has Remark 4, Subsection 2.2 has Definition 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify macros and commands to replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors usually define a lot of custom commands and macros in their LaTeX files. Such customizations vary from author to author and most customized commands are not recognized by Obsidian. \n",
    "\n",
    "See `nbs/_tests/latex_examples/commands_example/main.tex` for some examples of custom commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def custom_newcommands(\n",
    "        preamble: str, # The preamble of a LaTeX document.\n",
    "        ) -> dict[str, tuple[int, Union[str, None], str]]: # The keys are the names of the newly defined commands and the values are tuples consisting of 1. the number of parameters 2. The default argument if specified or `None` otherwise, and 3. the display text of the command.\n",
    "    \"\"\"\n",
    "    Return a dict mapping commands defined in `preamble` to the number of arguments\n",
    "    display text of the commands.\n",
    "\n",
    "    Assumes that the newcommands only have at most one default parameter (newcommands with\n",
    "    multiple default parameters are not valid in LaTeX).\n",
    "\n",
    "    Ignores all comented newcommands.\n",
    "    \"\"\"\n",
    "    preamble = remove_comments(preamble)\n",
    "    newcommand_regex = regex.compile(\n",
    "        r'(?<!%)\\s*\\\\(?:re)?newcommand\\s*\\{\\\\\\s*(\\w+)\\s*\\}\\s*(\\[(\\d+)\\]\\s*(?:\\[(\\w+)\\])?)?\\s*\\{((?>[^{}]+|\\{(?5)\\})*)\\}', re.MULTILINE)\n",
    "    # newcommand_regex = regex.compile(\n",
    "    #     r'(?<!%)\\s*\\\\(?:re)?newcommand\\s*\\{\\\\\\s*(\\w+)\\s*\\}\\s*(\\[(\\d+)\\]\\s*(?:\\[(\\w+)\\])?)?\\s*\\{\\s*(.*)\\s*\\}', re.MULTILINE)\n",
    "    commands = {}\n",
    "    for match in newcommand_regex.finditer(preamble):\n",
    "        name = match.group(1)\n",
    "        num_args = match.group(3)\n",
    "        optional_default_arg = match.group(4)\n",
    "        definition = match.group(5)\n",
    "\n",
    "        # Convert the number of arguments to an integer, if it was specified\n",
    "        if num_args is not None:\n",
    "            num_args = int(num_args)\n",
    "        else:\n",
    "            num_args = 0\n",
    "\n",
    "        commands[name] = (num_args, optional_default_arg, definition)\n",
    "    return commands\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "text_1 = r'\\newcommand{\\con}{\\mathcal{C}}'\n",
    "test_eq(custom_newcommands(text_1), {'con': (0, None, r'\\mathcal{C}')})\n",
    "\n",
    "# With a parameter\n",
    "text_2 = r'\\newcommand{\\field}[1]{\\mathbb{#1}}'\n",
    "test_eq(custom_newcommands(text_2), {'field': (1, None, r'\\mathbb{#1}')}) \n",
    "\n",
    "# With multiple parameters, the first of which has a default value of `2`\n",
    "text_3 = r'\\newcommand{\\plusbinomial}[3][2]{(#2 + #3)^#1}'\n",
    "test_eq(custom_newcommands(text_3), {'plusbinomial': (3, '2', r'(#2 + #3)^#1')}) \n",
    "\n",
    "# The display text has backslashes `\\` and curly brances `{}``\n",
    "text_4 = r'\\newcommand{\\beq}{\\begin{displaymath}}'\n",
    "test_eq(custom_newcommands(text_4), {'beq': (0, None, '\\\\begin{displaymath}')})\n",
    "\n",
    "\n",
    "# Basic with spaces in the newcommand declaration\n",
    "text_6 = r'\\newcommand {\\con}  {\\mathcal{C}}'\n",
    "test_eq(custom_newcommands(text_6), {'con': (0, None, r'\\mathcal{C}')})\n",
    "\n",
    "# With a parameter and spaces in the newcommand declaration\n",
    "text_7 = r'\\newcommand   {\\field}   [1] {\\mathbb{#1}}'\n",
    "test_eq(custom_newcommands(text_7), {'field': (1, None, r'\\mathbb{#1}')}) \n",
    "\n",
    "# With multiple parameters, a default value, and spaces in the newcommand declaration\n",
    "text_8 = r'\\newcommand {\\plusbinomial} [3] [2] {(#2 + #3)^#1}'\n",
    "test_eq(custom_newcommands(text_8), {'plusbinomial': (3, '2', r'(#2 + #3)^#1')}) \n",
    "\n",
    "# With a comment `%`\n",
    "text_9 = r'% \\newcommand{\\con}{\\mathcal{C}}'\n",
    "test_eq(custom_newcommands(text_9), {})\n",
    "\n",
    "\n",
    "# Spanning multiple lines\n",
    "text_10 = r'''\\newcommand{\\mat}[4]{\\left[\\begin{array}{cc}#1 & #2 \\\\\n",
    "                                         #3 & #4\\end{array}\\right]}'''\n",
    "test_eq(\n",
    "    custom_newcommands(text_10),\n",
    "    {'mat': (4, None,\n",
    "             '\\\\left[\\\\begin{array}{cc}#1 & #2 \\\\\\\\\\n                                         #3 & #4\\\\end{array}\\\\right]')})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def custom_mathoperators(\n",
    "        preamble: str, # The preamble of a LaTeX document.\n",
    "        ) -> dict[str, tuple[int, None, str]]: # The keys are the names of the newly defined commands and the values are tuples consisting of 1. the number of arguments and 2. the display text of the command.\n",
    "    \"\"\"\n",
    "    Return a dict mapping commands defined in `preamble` to the number of arguments\n",
    "    display text of the commands.\n",
    "    \"\"\"\n",
    "    declaremathoperator_regex = re.compile(r'\\\\DeclareMathOperator\\s*\\{\\\\\\s*(\\w+)\\s*\\}\\s*\\{\\s*(.*)\\s*\\}')\n",
    "    commands = {}\n",
    "    for match in declaremathoperator_regex.finditer(preamble):\n",
    "        name = match.group(1)\n",
    "        definition = match.group(2)\n",
    "\n",
    "        commands[name] = (0, None, definition)\n",
    "    return commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = r'\\DeclareMathOperator{\\Hom}{Hom}'\n",
    "test_eq(custom_mathoperators(text_1), {'Hom': (0, None, 'Hom')})\n",
    "\n",
    "text_2 = r'\\DeclareMathOperator{\\tConf}{\\widetilde{Conf}}'\n",
    "test_eq(custom_mathoperators(text_2), {'tConf': (0, None, r'\\widetilde{Conf}')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use a regexp pattern like this one to extract balanced curly braces\n",
    "# \\\\mat\\{((?>[^{}]+|\\{(?1)\\})*)\\}\\{((?>[^{}]+|\\{(?2)\\})*)\\}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def regex_pattern_detecting_command(\n",
    "        command_name: str,\n",
    "        command_tuple: tuple[int, Union[None, str], str], # Consists of 1. the number of parameters 2. The default argument if specified or `None`, and 3. the display text of the command.\n",
    "        ) -> regex.Pattern:\n",
    "    \"\"\"Return a `regex.pattern` object (not a `re.pattern` object) detecting\n",
    "    the command with the specified number of parameters, optional argument,\n",
    "    and display text.\n",
    "\n",
    "    Assumes that the curly braces used to write the invocations of the commands\n",
    "    are balanced and properly nested. Assumes that there are no two commands\n",
    "    of the same name.\n",
    "    \"\"\"\n",
    "    num_parameters, optional_arg, _ = command_tuple\n",
    "    backslash_name = fr\"\\\\{command_name}\"\n",
    "    optional_argument_detection = fr\"(?:\\[(.*?)\\])?\" if optional_arg is not None else \"\"\n",
    "    argument_detection = r\"\"\n",
    "    if optional_arg is not None:\n",
    "        pattern = f\"{backslash_name}\\\\s*(?:{optional_argument_detection})\"\n",
    "        trailing_arguments = [_argument_detection(i) for i in range(2, 1+num_parameters)]\n",
    "        trailing_args_pattern = \"\\\\s*\".join(trailing_arguments)\n",
    "        pattern = (f\"{pattern}\\\\s*{trailing_args_pattern}\")\n",
    "    elif num_parameters > 0:\n",
    "        arguments = [_argument_detection(i) for i in range(1, 1+num_parameters)]\n",
    "        args_pattern = \"\\\\s*\".join(arguments)\n",
    "        pattern = f\"{backslash_name}\\\\s*{args_pattern}\"\n",
    "    else:\n",
    "        pattern = f\"{backslash_name}\"\n",
    "    return regex.compile(pattern)\n",
    "\n",
    "def _argument_detection(group_num: int):\n",
    "    return \"\\{((?>[^{}]+|\\{(?1)\\})*)\\}\".replace(\"1\", str(group_num))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = regex_pattern_detecting_command('Sur', (0, None, r'\\mathrm{Sur}'))\n",
    "text = r'The number of element of $\\Sur(\\operatorname{Cl} \\mathcal{O}_L, A)$ is ...'\n",
    "match = pattern.search(text)\n",
    "start, end = match.span()\n",
    "test_eq(text[start:end], r'\\Sur')\n",
    "\n",
    "pattern = regex_pattern_detecting_command('field', (1, None, r'\\mathbb{\\#1}'))\n",
    "text = r'\\field{Q}'\n",
    "# print(pattern.pattern)\n",
    "match = pattern.search(text)\n",
    "start, end = match.span()\n",
    "test_eq(text[start:end], text)\n",
    "\n",
    "\n",
    "pattern = regex_pattern_detecting_command('mat', (4, None, r'\\left[\\begin{array}{cc}#1 & #2 \\\\ #3 & #4\\end{array}\\right]'))\n",
    "text = r'\\mat{{123}}{asdfasdf{}{}}{{{}}}{{asdf}{asdf}{}}' # This is a balanced str.\n",
    "match = pattern.search(text)\n",
    "start, end = match.span()\n",
    "test_eq(text[start:end], text)\n",
    "test_eq(match.group(1), r'{123}')\n",
    "\n",
    "pattern = regex_pattern_detecting_command('plusbinomial', (3, '2', r'(#2 + #3)^#1'))\n",
    "text = r'\\plusbinomial{x}{y}'\n",
    "match = pattern.search(text)\n",
    "start, end = match.span()\n",
    "test_eq(text[start:end], text)\n",
    "\n",
    "text = r'\\plusbinomial[4]{x}{y}'\n",
    "match = pattern.search(text)\n",
    "start, end = match.span()\n",
    "test_eq(text[start:end], text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def replace_commands_in_latex_document(\n",
    "        docment: str, \n",
    "        command_dict: dict[str, tuple[int, Union[None, str], str]]\n",
    "        ) -> str:\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def custom_commands(text: str) -> list[dict[str, Union[str, int]]]:\n",
    "    # TODO: test that commented out custom commands are not used.\n",
    "    \"\"\"Returns a dict of custom commands/macros/operators in a latex document\n",
    "    along with their corresponding definitions.\n",
    "    \n",
    "    Assumes that the document's `\\begin{document}` invocation (if it exists)\n",
    "    is in its own line. The preamble (particularly the definitions of the\n",
    "    commands/macros) may be commented. In this case, the format of the\n",
    "    comments should be `%<definition of the command/macro/operat>`, i.e.\n",
    "    the comment should start with a single comment symbol `%` and should not\n",
    "    have any characters in between the comment symbol and the definition of\n",
    "    the command/macro/operator.\n",
    "    \n",
    "    TODO: Make it so that commands that depend on other commands are\n",
    "    fully decoded - e.g. boggess-sankar has the command `\\tunignsheaf`\n",
    "    which depends on the custom commands `\\ol` and `\\cV`.\n",
    "    \n",
    "    **Parameters**\n",
    "    - text - str\n",
    "        - The text of a LaTeX document. This should at least contain the\n",
    "        preamble of the document.\n",
    "        \n",
    "    **Returns**\n",
    "    - list[dict[str, Union[str, int]]]\n",
    "        - For each dict, the keys include `'name'`, `'format'`, and\n",
    "        optionally `'num_params'`, `'default_argument'`. The values\n",
    "        are the command name (without the starting backslashes),\n",
    "        format of the output of the command, the number of parameters\n",
    "        that the command must take (if any), and the number of\n",
    "        optional parameters that the command takes.\n",
    "    \"\"\"\n",
    "    text = preamble_text(text)\n",
    "    lines = text.split('\\n')\n",
    "    lines = [line for line in lines if _type_of_line(line)]\n",
    "    custom_names_and_defs = [_custom_name_and_def(line) for line in lines]\n",
    "    custom_names_and_defs = [custom for custom in custom_names_and_defs\n",
    "                             if custom]\n",
    "    return custom_names_and_defs\n",
    "    \n",
    "    \n",
    "def preamble_text(text: str) -> str:\n",
    "    \"\"\"Returns the preamble text of a LaTeX document text, i.e. the text before\n",
    "    the `\\begin{document}`.\n",
    "    \n",
    "    **Parameters**\n",
    "    - text - str\n",
    "        - The LaTeX document text\n",
    "        \n",
    "    **Returns**\n",
    "    - str\n",
    "        - The preamble of the LaTeX documen text.\n",
    "    \"\"\"\n",
    "    matches = find_regex_in_text(text, pattern=r'\\\\begin\\{document\\}')\n",
    "    if not matches:\n",
    "        return text\n",
    "    else:\n",
    "        start, _ = matches[0]\n",
    "        return text[:start]\n",
    "             \n",
    "             \n",
    "def _type_of_line(line: str) -> Union[str, None]:\n",
    "    \"\"\"Returns the type of LaTeX preamble line.\n",
    "    \n",
    "    **Parameters**\n",
    "    - line - str\n",
    "\n",
    "    **Returns**\n",
    "    - Union[str, None]\n",
    "        - one of `'command'`, `'mathoperator'`, `'def'`, `'mathtext'`,\n",
    "        or `None`.\n",
    "    \"\"\"\n",
    "    if find_regex_in_text(line, pattern=r'%?\\\\(re)?newcommand'):\n",
    "        return 'command'\n",
    "    elif find_regex_in_text(line, pattern=r'%?\\\\DeclareMathOperator'):\n",
    "        return 'mathoperator'\n",
    "    elif find_regex_in_text(line, pattern=r'%?\\\\def'):\n",
    "        return 'def'\n",
    "    return None\n",
    "\n",
    "\n",
    "def _custom_name_and_def(line: str)\\\n",
    "        -> Union[dict[str, Union[str, int]], None]:\n",
    "    if _type_of_line(line) == 'command':\n",
    "        return _command_name_and_def(line)\n",
    "    elif _type_of_line(line) == 'mathoperator':\n",
    "        return _math_operator_name_and_def(line)\n",
    "    elif _type_of_line(line) == 'def':\n",
    "        return _def_name_and_def(line)\n",
    "    # elif _type_of_line(line) == 'mathtext':\n",
    "    #     return _mathtext_name_and_def(line)\n",
    "        \n",
    "def _command_name_and_def(line: str) -> dict[str, Union[str, int]]:\n",
    "    \"\"\"Returns a dict containing 1. the name of the command and 2.\n",
    "    How the command manifests, including any inputs.\n",
    "    \n",
    "    See https://www.overleaf.com/learn/latex/Commands#Defining_a_new_command\n",
    "    for how LaTeX commands are defined.\n",
    "    \n",
    "    **Returns**\n",
    "    - dict\n",
    "        - The keys include 'name', 'format', and optionally\n",
    "        'num_params', 'default_argument'. The values are the command\n",
    "        name, format of the output of the command, the number of parameters\n",
    "        that the command must take (if any), and the number of optional\n",
    "        parameters that the command takes.\n",
    "    \"\"\"\n",
    "    match = re.search(\n",
    "        r'^(?<!%)\\\\(?:re)?newcommand(?:\\{| *)\\\\([^\\{\\}\\] ]*)(?: *?|\\})(?:\\[(\\d+)\\])?'\n",
    "        r'(?:\\[(\\d+)\\])?\\{(.*?)\\}[\\s]*$', line)\n",
    "    # match = re.search(\n",
    "    #     r'^%?\\\\(?:re)?newcommand(?:\\{| *)\\\\([^\\{\\}\\] ]*)(?: *?|\\})(?:\\[(\\d+)\\])?'\n",
    "    #     r'(?:\\[(\\d+)\\])?\\{(.*?)\\}[\\s]*$', line)\n",
    "    if match:\n",
    "        command_dict = {'name': match.group(1), 'format': match.group(4)}\n",
    "        if match.group(2):\n",
    "            command_dict['num_params'] = int(match.group(2))\n",
    "        if match.group(3):\n",
    "            command_dict['default_argument'] = match.group(3)\n",
    "        return command_dict\n",
    "    else:\n",
    "        # print(line)\n",
    "        return None\n",
    "\n",
    "def _math_operator_name_and_def(line: str) -> dict[str, Union[str, int]]:\n",
    "    match = re.search(\n",
    "        r'^%?\\\\DeclareMathOperator(?:\\{| *)\\\\([^\\{\\}\\] ]*)(?: *?|\\})'\n",
    "        '\\{(.*?)\\}[\\s]*$', line)\n",
    "    if match:\n",
    "        command_dict = {'name': match.group(1),\n",
    "                        'format': f'\\\\operatorname{{{match.group(2)}}}'}\n",
    "        return command_dict\n",
    "    else:\n",
    "        # print(line)\n",
    "        return None\n",
    "\n",
    "def _def_name_and_def(line: str) -> dict[str, Union[str, int]]:\n",
    "    match = re.search(\n",
    "        r'^%?\\\\def(?:\\{| *)\\\\([^\\{\\}\\] ]*)(?: *?|\\})\\{(.*?)\\}[\\s]*$', line)\n",
    "    if match:\n",
    "        command_dict = {'name': match.group(1),\n",
    "                        'format': match.group(2)}\n",
    "        return command_dict\n",
    "    else:\n",
    "        # print(line)\n",
    "        return None\n",
    "\n",
    "# def _mathtext_name_and_def(line: str) -> dict[str, Union[str, int]]:\n",
    "#     match = re.search(\n",
    "#         r'%?\\\\DeclareMathOperator(?:\\{| *)([^\\{\\}\\] ]*)(?: *?|\\})\\{(.*?)\\} *$', line)\n",
    "# def _simple_command_name_and_def(line: str) -> dict[str]:\n",
    "#     match = re.search(\n",
    "#         r'%?\\\\newcommand(?:\\{| *)([^\\} ]*)(?: *|\\})\\{(.*?)\\} *$', line)\n",
    "#     return match.group(1), match.group(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hide\n",
    "# import unittest\n",
    "# class CustomCommandsHelperUnitTest(unittest.TestCase):\n",
    "#     def test_type_of_line(self):\n",
    "#         self.assertEqual(_type_of_line(r'%\\newcommand \\X {{\\cal X}}'), 'command')\n",
    "#         self.assertEqual(_type_of_line(r'\\newcommand \\X {{\\cal X}}'), 'command')\n",
    "#         self.assertEqual(_type_of_line(r'\\newcommand  \\QQ {{\\mathbb Q}}'), 'command')\n",
    "#         self.assertEqual(_type_of_line(r'%\\newcommand \\CM {{\\cal M}}'), 'command')\n",
    "#         self.assertEqual(_type_of_line(r'%\\renewcommand{\\P}{\\ensuremath{{\\mathbb{P}}}}'), 'command')\n",
    "#         self.assertEqual(_type_of_line(r'%\\def\\subsectie{\\emppsubsection[]{\\unskip}}'), 'def')\n",
    "\n",
    "        \n",
    "#     def test_command_name_and_def(self):\n",
    "#         self.assertDictEqual(\n",
    "#             _command_name_and_def(r'%\\newcommand \\X {{\\cal X}}'),\n",
    "#             {'name': r'X', 'format': r'{\\cal X}'})\n",
    "#         self.assertDictEqual(\n",
    "#             _command_name_and_def(r'%\\newcommand \\val {\\mathop{\\rm val}}'),\n",
    "#             {'name': r'val', 'format': r'\\mathop{\\rm val}'})\n",
    "#         self.assertDictEqual(\n",
    "#             _command_name_and_def(r'\\newcommand{\\colim}{\\mathop{\\mathrm{colim}}}'),\n",
    "#             {'name': r'colim', 'format': r'\\mathop{\\mathrm{colim}}'})\n",
    "#         self.assertDictEqual(\n",
    "#             _command_name_and_def(r'\\newcommand{\\G}{\\mathbb G}'),\n",
    "#             {'name': r'G', 'format': '\\mathbb G'})\n",
    "#         self.assertDictEqual(\n",
    "#             _command_name_and_def(r'\\newcommand{\\al}[1]{\\overline{#1}}'),\n",
    "#             {'name': r'al', 'num_params': 1, 'format': '\\overline{#1}'})\n",
    "#         self.assertDictEqual(\n",
    "#             _command_name_and_def(r'\\newcommand{\\barEll}[1]{\\overline{\\operatorname{Ell}}_{#1}}'),\n",
    "#             {'name': r'barEll', 'num_params': 1, 'format': '\\overline{\\operatorname{Ell}}_{#1}'})\n",
    "#         self.assertDictEqual(\n",
    "#             _command_name_and_def(r'%\\newcommand{\\plusbinomial}[3][2]{(#2 + #3)^#1}'),\n",
    "#             {'name': r'plusbinomial', 'num_params': 3, 'default_argument': '2', 'format': r'(#2 + #3)^#1'})\n",
    "#         self.assertDictEqual(\n",
    "#             _command_name_and_def(r'%\\newcommand\\mx[1]{\\ensuremath{\\begin{pmatrix}#1\\end{pmatrix}}}'),\n",
    "#             {'name': r'mx', 'num_params': 1, 'format': r'\\ensuremath{\\begin{pmatrix}#1\\end{pmatrix}}'})\n",
    "#         self.assertDictEqual(\n",
    "#             _command_name_and_def(r'%\\renewcommand{\\bar}[1]{{\\overline{#1}}}'),\n",
    "#             {'name': r'bar', 'num_params': 1, 'format': r'{\\overline{#1}}'})\n",
    "#         self.assertIsNone(\n",
    "#             _command_name_and_def(r'%%\\newcommand{}{\\unskip\\nolinebreak\\hfill\\hbox{\\quad $\\square$}}'))\n",
    "#         self.assertIsNone(\n",
    "#             _command_name_and_def(r'%%\\newcommand{}{\\unskip\\nolinebreak\\hfill\\hbox{\\quad $\\square$}}'))\n",
    "                \n",
    "#     def test_math_operator_name_and_def(self):\n",
    "#         self.assertDictEqual(\n",
    "#             _math_operator_name_and_def(r'%\\DeclareMathOperator{\\spec}{Spec}'),\n",
    "#             {'name': r'spec', 'format': r'\\operatorname{Spec}'})\n",
    "#         self.assertDictEqual(\n",
    "#             _math_operator_name_and_def(r'%\\DeclareMathOperator{\\sg}{SG}'),\n",
    "#             {'name': r'sg', 'format': r'\\operatorname{SG}'})\n",
    "#         self.assertIsNone(\n",
    "#             _math_operator_name_and_def(r'%%\\DeclareMathOperator{\\sp}{Sp}'))\n",
    "#         self.assertIsNone(\n",
    "#             _math_operator_name_and_def(r'%%\\DeclareMathOperator{\\std}{std}'))\n",
    "#         self.assertIsNone(\n",
    "#             _math_operator_name_and_def(r'%%\\DeclareMathOperator{\\u}{U}'))\n",
    "\n",
    "\n",
    "#     def test_def_name_and_def(self):\n",
    "#         self.assertDictEqual(\n",
    "#             _def_name_and_def(r'%\\def\\dual{^\\vee}'),\n",
    "#             {'name': r'dual', 'format': r'^\\vee'})\n",
    "#         self.assertDictEqual(\n",
    "#             _def_name_and_def(r'%\\def\\inv{^{-1}}'),\n",
    "#             {'name': r'inv', 'format': r'^{-1}'})\n",
    "#         self.assertDictEqual(\n",
    "#             _def_name_and_def(r'%\\def\\integ{\\mathbb Z}'),\n",
    "#             {'name': r'integ', 'format': r'\\mathbb Z'})\n",
    "#         self.assertDictEqual(\n",
    "#             _def_name_and_def(r'%\\def\\smooth{{\\rm sm}}\t\t'),\n",
    "#             {'name': r'smooth', 'format': r'{\\rm sm}'})\n",
    "        \n",
    "# unittest.main(argv=[''], verbosity=1, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
