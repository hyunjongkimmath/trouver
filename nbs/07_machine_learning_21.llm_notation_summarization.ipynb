{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0163e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp machine_learning.llm_notation_summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403608ef",
   "metadata": {},
   "source": [
    "# machine_learning.llm_notation_summarization\n",
    "> Functions for summarizing notations using a large language model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8cb6a0",
   "metadata": {},
   "source": [
    "Previously, `trouver` used fine-tuned Transformers based models (Specifically Google's T5) to summarize notation. However, procuring high quality data is highly time consuming for this approach and the fine-tuned models have yet produce generally competent predictions.\n",
    "\n",
    "This module instead opts to use large language models (LLM's)/generative AI models for the summarization task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee1eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from os import PathLike\n",
    "from typing import Optional, TypedDict\n",
    "import re\n",
    "\n",
    "import lmstudio as lms\n",
    "from lmstudio import LLM\n",
    "\n",
    "from trouver.obsidian.file import MarkdownFile, MarkdownLineEnum\n",
    "\n",
    "from trouver.machine_learning.notation_summarization import _summary_should_be_generated, _get_summary, get_latex_in_original_from_parsed_notation_note_data, single_input_for_notation_summarization, notation_summarization_data_from_note, _write_summary_to_notation_note, format_training_tokens, format_for_gemma_instruct\n",
    "\n",
    "\n",
    "from trouver.personal_vault.note_processing import process_standard_information_note\n",
    "from trouver.notation.parse import main_of_notation, parse_notation_note\n",
    "from trouver.obsidian.vault import VaultNote\n",
    "\n",
    "from trouver.obsidian.links import links_from_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ba6d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trouver.helper.tests import _test_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7cc36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# --- 1. SYSTEM PROMPT (TARGET + TEXT SPLIT) ---\n",
    "NOTATION_SUMMARIZATION_SYSTEM_PROMPT = r\"\"\"\n",
    "# Role\n",
    "You are a strict, non-conversational mathematical compiler. Your task is to extract a rigorous definition summary from the provided text for a specific **Target Symbol**.\n",
    "\n",
    "# Input Data\n",
    "1.  **Text:** The raw mathematical excerpt containing the definition.\n",
    "2.  **Target:** The specific notation to extract and define from the text above.\n",
    "\n",
    "# Goal\n",
    "Generate the prose continuation of a sentence starting with: \"$SYMBOL$ [[SOURCE|denotes]]...\"\n",
    "**Start your output immediately with the noun phrase.** The output must be mathematically precise, grammatically correct prose where all mathematics in valid MathJax/LaTeX that is renderable in Obsidian.md markdown.\n",
    "\n",
    "# Generation Rules\n",
    "\n",
    "## 1. The \"Identity Signature\"\n",
    "- **Priority:** Use the formal name if given (e.g., \"the norm,\" \"the sheaf of differentials\").\n",
    "- **Parent Context:** Immediately link the symbol to its primary parameters in the first sentence (e.g., \"of a morphism $f$,\" \"of an ideal $\\mathfrak{a}$\").\n",
    "\n",
    "## 2. The Operational Definition\n",
    "- Explain **how** it is constructed using the **exact abstraction level** of the text.\n",
    "- **Justification:** Keep \"because\" clauses that explain well-definedness (e.g., \"finite because it is full-rank\").\n",
    "- **Procedural Logic:** If the text lists steps (1, 2, 3), use a numbered list.\n",
    "- **Formulas:** Include the defining equation.\n",
    "\n",
    "## 3. Context Reconstruction (\"Where\" Clause) \n",
    "- **Recursive Unwinding:** Do not just list variables; **briefly define them**.   \n",
    "- *Bad:* \"...where $cl_X$ is the cycle class map.\"  \n",
    "- *Good:* \"...where $cl_X: CH^i(X) \\to H^{2i}(X)$ is the cycle class map.\"\n",
    " - **Integration:** Use a \"where...\" clause immediately following the definition to define variables like $K, \\mathcal{O}_K$, $X, Y$.\n",
    "\n",
    "## 4. Structural Characterizations\n",
    "- **New Paragraph:** Start a new paragraph for distinct properties or theorems.\n",
    "- **Subject Focus:** Only include statements that describe the target symbol itself.\n",
    "- **Negative Constraint:** Do not include definitions of *other* concepts (like \"Catenary Ring\") just because they mention the target symbol.\n",
    "\n",
    "## 5. Constraints\n",
    "- **Tone:** Clinical, precise. No \"We defined,\" \"Note that.\"\n",
    "- **Safety:** ABSOLUTELY NO EMOJIS. NO MARKDOWN CODE BLOCKS.\n",
    "\n",
    "## 6. LaTeX Standardization (MANDATORY)\n",
    "- **Error Correction:** You must fix syntactic errors in the input. If the text has `\\frac a b` (ambiguous) or `\\alph` (typo), output correct standard LaTeX: `\\frac{a}{b}`, `\\alpha`.\n",
    "- **Obsidian Format:**\n",
    "  - Use `$` for inline math.\n",
    "  - Use `$$` for block math/equations.\n",
    "  - Use `$$\\begin{align*} ... \\end{align*}$$` for multi-line definitions.\n",
    "  - NEVER use `\\(` `\\)` `\\[` `\\]`.\n",
    "- **Notation:**\n",
    "  - Convert plain text operators to commands: \"Gal\" -> `\\operatorname{Gal}`, \"Hom\" -> `\\operatorname{Hom}` (or use \\mathrm or \\mathbf, etc. as appropriate for the text).\n",
    "\n",
    "## 7. Input Sanitization\n",
    "\n",
    "    Text Cleaning: If the input text contains typos (e.g., \"morphism off schemes\", \"defind as\"), correct the spelling in your prose output.\n",
    "\n",
    "    Variable Consistency: If the input text uses inconsistent notation for the same object (e.g., switching between $\\epsilon$ and $\\varepsilon$ randomly), standardize to the most common or standard usage in the definition.\n",
    "\n",
    "    Noise Removal: Ignore filler words like \"clearly,\" \"obviously,\" or conversational asides found in the source text.\n",
    "---\n",
    "\n",
    "# Example 1: Constructive Object\n",
    "**Text:**\n",
    "Let $f: X \\to Y$ be a morphism of schemes... The sheaf of relative differentials, denoted $\\Omega_{X/Y}$, is then defined to be the pullback of this conormal sheaf... That is, $\\Omega_{X/Y} := \\Delta^*(\\mathcal{I}/\\mathcal{I}^2)$.\n",
    "**Target:** \\Omega_{X/Y}\n",
    "**Output:**\n",
    "the sheaf of relative differentials of a morphism $f: X \\to Y$ of schemes. It is defined as the pullback $\\Omega_{X/Y} := \\Delta^*(\\mathcal{I}/\\mathcal{I}^2)$, where $\\mathcal{I}$ is the ideal sheaf of the diagonal immersion $\\Delta: X \\to X \\times_Y X$. Since the conormal sheaf $\\mathcal{I}/\\mathcal{I}^2$ is a sheaf on the diagonal $\\Delta(X)$ (viewed as a sheaf on $X$), the result is a sheaf on $X$.\n",
    "\n",
    "An important property is that for affine open subschemes $U \\subseteq X$ and $V \\subseteq Y$ with $f(U) \\subseteq V$, the sections $\\Omega_{X/Y}(U)$ are isomorphic to the module of relative differentials $\\Omega_{A/R}$.\n",
    "\n",
    "# Example 2: Property/Value\n",
    "**Text:**\n",
    "Let $K$ be a number field... We define the norm of an ideal $\\mathfrak{a}$, denoted $N(\\mathfrak{a})$, to be the cardinality of the quotient ring $\\mathcal{O}_K / \\mathfrak{a}$. Since $\\mathfrak{a}$ is a full-rank sublattice of $\\mathcal{O}_K$, this quotient ring is always finite.\n",
    "**Target:** N(\\mathfrak{a})\n",
    "**Output:**\n",
    "the norm of a non-zero ideal $\\mathfrak{a}$ in the ring of integers $\\mathcal{O}_K$ of a number field $K$. It is defined as the cardinality of the quotient ring $N(\\mathfrak{a}) := |\\mathcal{O}_K / \\mathfrak{a}|$. This quotient is always finite because $\\mathfrak{a}$ is a full-rank sublattice of $\\mathcal{O}_K$.\n",
    "\n",
    "The norm is a completely multiplicative function, meaning $N(\\mathfrak{a}\\mathfrak{b}) = N(\\mathfrak{a})N(\\mathfrak{b})$ for any non-zero ideals $\\mathfrak{a}, \\mathfrak{b}$.\n",
    "\n",
    "# Example 3: Procedural Definition\n",
    "**Text:**\n",
    "Thus if $D \\in \\operatorname{Div}(V)$ is a divisor and we want to choose a particular height function $h_{V, D}$, we need to make the following choices:\n",
    "[1] Choose very ample divisors $D_{1}$ and $D_{2}$ with $D=D_{1}-D_{2}$.\n",
    "...\n",
    "**Target:** h_{V,D}\n",
    "**Output:**\n",
    "a particular height function for a divisor $D$ on a variety $V$. It is defined by the following construction:\n",
    "1. Choose very ample divisors $D_{1}$ and $D_{2}$ such that $D=D_{1}-D_{2}$.\n",
    "2. Choose embeddings $\\phi_{1}: V \\rightarrow \\mathbb{P}^{n}$ and $\\phi_{2}: V \\rightarrow \\mathbb{P}^{m}$ corresponding respectively to $D_{1}$ and $D_{2}$.\n",
    "3. Set $h_{V, D}(P)=h\\left(\\phi_{1}(P)\\right)-h\\left(\\phi_{2}(P)\\right)$.\n",
    "\n",
    "# Example 4: Inconsistency Standardization\n",
    "**Text:**\n",
    "The set of morphisms between schemes X and Y is usually writen Hom(X,Y). We say that a morphism $f \\in \\operatorname{Hom}(X, Y)$ is separated if the diagonal is a closed immersion.\n",
    "**Target:** \\operatorname{Hom}(X,Y)\n",
    "**Output:**\n",
    "the set of morphisms between schemes $X$ and $Y$. \n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5196c132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def example_from_notation_note(\n",
    "        notation_note: VaultNote\n",
    "        ) -> dict[str, str]: # Keys include 'processed_main_note_content' and 'latex_in_original'\n",
    "    \"\"\"\n",
    "    Helper to parse `notation_note` and gather data for summarization.\n",
    "    \n",
    "    This function extracts the LaTeX used in the original main note and \n",
    "    retrieves the processed content of that main note.\n",
    "    \"\"\"\n",
    "    parsed = parse_notation_note(notation_note)\n",
    "\n",
    "    # Access the main note (the one where the notation is defined)\n",
    "    main_note = VaultNote(\n",
    "        vault=notation_note.vault, name=parsed.name_of_main_note)\n",
    "    \n",
    "    # Process the main note's content to remove metadata/formatting\n",
    "    main_note_mf = MarkdownFile.from_vault_note(main_note)\n",
    "    main_note_content = str(process_standard_information_note(main_note_mf, notation_note.vault))\n",
    "\n",
    "    # Identify the specific LaTeX string as it appeared in the source\n",
    "    latex_in_original = get_latex_in_original_from_parsed_notation_note_data(\n",
    "            parsed.yaml_frontmatter_meta, parsed.notation_str)\n",
    "    \n",
    "    # Extract existing summary data\n",
    "    summary_data = notation_summarization_data_from_note(\n",
    "        notation_note, notation_note.vault, check_for_actual_summarization=False)\n",
    "    \n",
    "    return summary_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f046d1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Note: number_theory_reference_1_Definition 1.7\n",
      "Content: The ring of integers modulo $n$, denoted $\\mathbb{Z}/n\\mathbb{Z}$ has the elements ...\n",
      "\n",
      "latex_in_original: $\\mathbb{Z}/n\\mathbb{Z}$\n"
     ]
    }
   ],
   "source": [
    "# Setup a path to your test vault\n",
    "test_vault_path = _test_directory() / 'test_vault_4'\n",
    "# Example notation note: 'number_theory_reference_1_notation_Z_nZ_ring_of_integers_modulo_n'\n",
    "example_note = VaultNote(test_vault_path, name='number_theory_reference_1_notation_Z_nZ_ring_of_integers_modulo_n')\n",
    "\n",
    "# Run the helper\n",
    "data = example_from_notation_note(example_note)\n",
    "\n",
    "# print(data.keys)\n",
    "# print(f\"Notation: {data['notation']}\")\n",
    "print(f\"Main Note: {data['main_note_name']}\")\n",
    "print(f\"Content: {data['processed_main_note_content']}\")\n",
    "print(f\"latex_in_original: {data['latex_in_original']}\")\n",
    "# Output would show the extracted dictionary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab101c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_eq, test_is\n",
    "\n",
    "# 1. Test basic functionality with a known note\n",
    "test_vault = _test_directory() / 'test_vault_4'\n",
    "note_name = r'number_theory_reference_1_notation_Z_nZ_ring_of_integers_modulo_n'\n",
    "notat_note = VaultNote(test_vault, name=note_name)\n",
    "\n",
    "res = example_from_notation_note(notat_note)\n",
    "\n",
    "# Verify expected keys in return dict\n",
    "expected_keys = {\"notation_note_name\", \"notation\", \"latex_in_original\", \"summary\", \"main_note_name\"}\n",
    "assert expected_keys.issubset(res.keys())\n",
    "\n",
    "# Verify specific values based on the vault content\n",
    "test_eq(res['main_note_name'], 'number_theory_reference_1_Definition 1.7')\n",
    "test_eq(res['notation'], r'$\\mathbb{Z}/n\\mathbb{Z}$')\n",
    "\n",
    "# 2. Test behavior with different check_for_actual_summarization logic\n",
    "# If the note isn't summarized yet, ensure the helper still returns data when False\n",
    "res_no_check = example_from_notation_note(notat_note)\n",
    "assert res_no_check is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e52287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#| export\n",
    "# def notation_note_should_be_summarized(\n",
    "#         notation_note: VaultNote,\n",
    "#         vault: PathLike,\n",
    "#         main_note: Optional[VaultNote] = None, # The main note from which the notation comes from. If this is `None`, then the `main_note` is obtained via the `main_of_notation` function.\n",
    "#         overwrite_previous_autogenerated_summary: bool = False, # If `True`, overwrite previously autogenerated summaries\n",
    "#         latex_in_original_comes_first: bool = True # This is a parameter to pass to calls to the `single_input_for_notation_summarization` function. If `True`, the `latex_in_original` piece appears before the `main_note_content`. While the default value of `True` is recommended, passing `False` to this parameter may be necessary to use the older version of the summarization model in the repo [`notation_summarizations_model`](https://huggingface.co/hyunjongkimmath/notation_summarizations_model).\n",
    "#     ) -> bool:\n",
    "#     r\"\"\"\n",
    "#     Return `True` if notation note has no summary or an autogenerated summary.\n",
    "\n",
    "#     Helper to tell\n",
    "#     \"\"\"\n",
    "#     metadata, notation_str, main_note_name,\\\n",
    "#         notation_note_content_mf, _\\\n",
    "#         = parse_notation_note(notation_note, vault)\n",
    "#     summary_should_be_generated, main_mf = _summary_should_be_generated(\n",
    "#         main_note, main_note_name, vault, notation_note,\n",
    "#         overwrite_previous_autogenerated_summary,\n",
    "#         metadata, notation_note_content_mf)\n",
    "#     return summary_should_be_generated\n",
    "\n",
    "def notation_note_should_be_summarized(\n",
    "        notation_note: VaultNote,\n",
    "        vault: PathLike,\n",
    "        main_note: Optional[VaultNote] = None, # The main note from which the notation comes from. If this is `None`, then the `main_note` is obtained via the `main_of_notation` function.\n",
    "        overwrite_previous_autogenerated_summary: bool = False, # If `True`, overwrite previously autogenerated summaries\n",
    "        latex_in_original_comes_first: bool = True # This is a parameter to pass to calls to the `single_input_for_notation_summarization` function. If `True`, the `latex_in_original` piece appears before the `main_note_content`. While the default value of `True` is recommended, passing `False` to this parameter may be necessary to use the older version of the summarization model in the repo [`notation_summarizations_model`](https://huggingface.co/hyunjongkimmath/notation_summarizations_model).\n",
    "    ) -> bool:\n",
    "    r\"\"\"\n",
    "    Return `True` if a notation note has no summary or contains an autogenerated summary that should be updated.\n",
    "\n",
    "    This helper determines if the note is a candidate for the summarization pipeline based on:\n",
    "    1. The presence of the `_auto/notation_summary` tag (if `overwrite_previous_autogenerated_summary` is True).\n",
    "    2. Whether the note currently lacks content beyond the \"denotes\" link.\n",
    "    3. Whether the main reference note actually exists and contains content.\n",
    "    \"\"\"\n",
    "    # parse_notation_note retrieves metadata, the notation string, and the main note's name\n",
    "    metadata, notation_str, main_note_name,\\\n",
    "        notation_note_content_mf, _\\\n",
    "        = parse_notation_note(notation_note, vault)\n",
    "        \n",
    "    # _summary_should_be_generated performs the logic of checking if the main note exists\n",
    "    # and if the notation note is already \"sufficiently summarized\" or tagged as auto-generated.\n",
    "    summary_should_be_generated, _ = _summary_should_be_generated(\n",
    "        main_note, main_note_name, vault, notation_note,\n",
    "        overwrite_previous_autogenerated_summary,\n",
    "        metadata, notation_note_content_mf)\n",
    "        \n",
    "    return summary_should_be_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f0530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needs summary: False\n"
     ]
    }
   ],
   "source": [
    "# Setup test environment\n",
    "test_vault = _test_directory() / 'test_vault_4'\n",
    "# A note that has already been summarized manually\n",
    "manual_note = VaultNote(test_vault, name='number_theory_reference_1_notation_Z_nZ_ring_of_integers_modulo_n')\n",
    "\n",
    "# Check if it needs summarization (it shouldn't, as it has manual content)\n",
    "needs_summary = notation_note_should_be_summarized(manual_note, test_vault)\n",
    "print(f\"Needs summary: {needs_summary}\") \n",
    "\n",
    "# A note that only has the \"denotes\" link and no actual explanation\n",
    "# empty_note = VaultNote(test_vault, name='some_new_unsummarized_notation')\n",
    "# print(f\"Empty note needs summary: {notation_note_should_be_summarized(empty_note, test_vault)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaef5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyunj\\Documents\\Development\\Python\\trouver\\trouver\\helper\\html.py:104: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  parsed_soup = BeautifulSoup(text, 'html.parser')\n",
      "C:\\Users\\hyunj\\Documents\\Development\\Python\\trouver\\trouver\\machine_learning\\notation_summarization.py:562: UserWarning: The notation note already has contents, so no new summary was added. Notation note name: number_theory_reference_1_notation_Z_nZ_ring_of_integers_modulo_n\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_eq\n",
    "import tempfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Test with existing summarized note\n",
    "test_vault = _test_directory() / 'test_vault_4'\n",
    "summarized_note = VaultNote(test_vault, name='number_theory_reference_1_notation_Z_nZ_ring_of_integers_modulo_n')\n",
    "\n",
    "# Should be False because it's already summarized and not tagged as _auto\n",
    "test_eq(notation_note_should_be_summarized(summarized_note, test_vault), False)\n",
    "\n",
    "# 2. Test with an auto-generated note\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    temp_path = Path(temp_dir)\n",
    "    shutil.copytree(test_vault, temp_path / 'vault')\n",
    "    v = temp_path / 'vault'\n",
    "    \n",
    "    # Simulate an auto-generated note by adding the tag\n",
    "    auto_note = VaultNote(v, name='number_theory_reference_1_notation_Z_nZ_ring_of_integers_modulo_n')\n",
    "    mf = MarkdownFile.from_vault_note(auto_note)\n",
    "    mf.add_tags(['_auto/notation_summary'])\n",
    "    mf.write(auto_note)\n",
    "    \n",
    "    # By default, it shouldn't overwrite\n",
    "    test_eq(notation_note_should_be_summarized(auto_note, v, overwrite_previous_autogenerated_summary=False), False)\n",
    "    \n",
    "    # With overwrite=True, it should return True\n",
    "    test_eq(notation_note_should_be_summarized(auto_note, v, overwrite_previous_autogenerated_summary=True), True)\n",
    "\n",
    "# 3. Test behavior when main note is missing\n",
    "# (Assuming 'non_existent_main' is referenced in a notation note)\n",
    "missing_main_note = VaultNote(test_vault, name='notation_with_missing_main_reference')\n",
    "if missing_main_note.exists():\n",
    "    test_eq(notation_note_should_be_summarized(missing_main_note, test_vault), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b114f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def separate_thoughts(raw_content: str):\n",
    "    \"\"\"\n",
    "    Separates model 'reasoning' from the actual answer.\n",
    "    Handles <think>, <thought>, and [THOUGHT] tags.\n",
    "    \"\"\"\n",
    "    # 1. Define common patterns for thinking blocks\n",
    "    # This regex looks for <think>...</think> or  (case insensitive)\n",
    "    tag_pattern = r\"<(think|thought)>([\\s\\S]*?)<\\/\\1>\"\n",
    "    \n",
    "    match = re.search(tag_pattern, raw_content, re.IGNORECASE)\n",
    "    \n",
    "    if match:\n",
    "        thoughts = match.group(2).strip()\n",
    "        # Remove the thinking block from the main content\n",
    "        answer = re.sub(tag_pattern, \"\", raw_content, flags=re.IGNORECASE).strip()\n",
    "        return thoughts, answer\n",
    "    \n",
    "    # 2. Fallback for models that don't use tags but use a header\n",
    "    if \"THOUGHTS:\" in raw_content.upper():\n",
    "        parts = re.split(r\"THOUGHTS:\", raw_content, flags=re.IGNORECASE)\n",
    "        # Assuming format: THOUGHTS: [logic] ANSWER: [result]\n",
    "        if \"ANSWER:\" in parts[1].upper():\n",
    "            sub_parts = re.split(r\"ANSWER:\", parts[1], flags=re.IGNORECASE)\n",
    "            return sub_parts[0].strip(), sub_parts[1].strip()\n",
    "            \n",
    "    # 3. If no markers found, return everything as the answer\n",
    "    return None, raw_content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a599ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1 = \"\"\"First, analyze the problem.<think>Step 1: Identify key components. Step 2: Validate inputs.</think> The final answer is 42.\"\"\"\n",
    "\n",
    "thoughts1, answer1 = separate_thoughts(ex1)\n",
    "test_eq(thoughts1, \"Step 1: Identify key components. Step 2: Validate inputs.\")\n",
    "test_eq(answer1, \"First, analyze the problem. The final answer is 42.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5014ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2 = \"\"\"<THOUGHT>\n",
    "Mathematical reasoning: check base cases first, then induction step.\n",
    "Edge case x=0 gives y=1.\n",
    "</THOUGHT>\n",
    "Final computation: ∫[0,1] x² dx = 1/3\"\"\"\n",
    "\n",
    "thoughts2, answer2 = separate_thoughts(ex2)\n",
    "test_eq(thoughts2, \"Mathematical reasoning: check base cases first, then induction step.\\nEdge case x=0 gives y=1.\")\n",
    "test_eq(answer2, \"Final computation: ∫[0,1] x² dx = 1/3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2386648",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex3 = \"\"\"THOUGHTS: Gal(L/K) is defined via étale cohomology. Verify separability first.\n",
    "ANSWER: The Galois group Gal(L/K) is finite of order [L:K].\"\"\"\n",
    "\n",
    "thoughts3, answer3 = separate_thoughts(ex3)\n",
    "test_eq(thoughts3, \"Gal(L/K) is defined via étale cohomology. Verify separability first.\")\n",
    "test_eq(answer3, \"The Galois group Gal(L/K) is finite of order [L:K].\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7977523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import *\n",
    "\n",
    "# Tag extraction works\n",
    "test_eq(separate_thoughts(\"<think>reasoning</think>\")[0], \"reasoning\")\n",
    "test_eq(separate_thoughts(\"<THOUGHT>test</thought>\")[0], \"test\")\n",
    "\n",
    "# Answer extraction - EXACT original behavior\n",
    "test_eq(separate_thoughts(\"A<think>B</think>C\")[1], \"AC\")\n",
    "test_eq(separate_thoughts(\"A <think>B</think> C\")[1], \"A  C\")\n",
    "test_eq(separate_thoughts(\"A\\n<think>B</think>\\nC\")[1], \"A\\n\\nC\")\n",
    "\n",
    "# Multiple tags - re.sub removes FIRST match + .strip()\n",
    "multi = \"<think>first</think>text<think>second</think>\"\n",
    "test_eq(separate_thoughts(multi)[0], \"first\")\n",
    "test_eq(separate_thoughts(multi)[1], \"text\")  # ← Fixed: .strip() removes trailing tag\n",
    "\n",
    "# No tags\n",
    "test_eq(separate_thoughts(\"plain text\")[0], None)\n",
    "test_eq(separate_thoughts(\"plain text\")[1], \"plain text\")\n",
    "\n",
    "# Malformed tags\n",
    "test_eq(separate_thoughts(\"<think>no close\")[0], None)\n",
    "test_eq(separate_thoughts(\"<think>no close\")[1], \"<think>no close\")\n",
    "\n",
    "# THOUGHTS:ANSWER: fallback\n",
    "test_eq(separate_thoughts(\"THOUGHTS: abc ANSWER: def\"), (\"abc\", \"def\"))\n",
    "\n",
    "# Empty cases\n",
    "test_eq(separate_thoughts(\"<think></think>\")[0], \"\")\n",
    "test_eq(separate_thoughts(\"\")[1], \"\")\n",
    "test_eq(separate_thoughts(\"   \")[1], \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fba37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# --- 2. CORE FUNCTIONS ---\n",
    "\n",
    "class SummaryResponse(TypedDict):\n",
    "    thoughts: str\n",
    "    output: str\n",
    "\n",
    "def generate_notation_summary(\n",
    "        model: LLM,\n",
    "        excerpt_text: str,\n",
    "        target_symbol: str,\n",
    "        max_context: int = 4096,\n",
    "        verbose: bool = True,\n",
    "        return_thoughts: bool = False,\n",
    "        system_prompt: str = NOTATION_SUMMARIZATION_SYSTEM_PROMPT,\n",
    "        ) -> str | SummaryResponse:\n",
    "    # 1. PRE-CALCULATE TOKENS FOR TRUNCATION\n",
    "    # Use Text -> Target order to favor caching\n",
    "    sys_tokens = len(model.tokenize(NOTATION_SUMMARIZATION_SYSTEM_PROMPT))\n",
    "    target_overhead = len(model.tokenize(f\"\\n\\nTarget Symbol: {target_symbol}\\nOutput:\"))\n",
    "    safety_margin = 500 \n",
    "    \n",
    "    available_for_text = max_context - sys_tokens - safety_margin - target_overhead\n",
    "    # excerpt_tokens = model.tokenize(excerpt_text)\n",
    "\n",
    "\n",
    "    # 2. SMART TRUNCATION (Using .decode instead of .detokenize)\n",
    "    # 2. SMART TRUNCATION\n",
    "    estimated_char_limit = available_for_text * 3\n",
    "    \n",
    "    if len(excerpt_text) > estimated_char_limit:\n",
    "        # Slice the string directly\n",
    "        excerpt_text = excerpt_text[:estimated_char_limit]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Warning: Excerpt truncated to {len(excerpt_text)} characters (approx. {available_for_text} tokens).\")\n",
    "\n",
    "\n",
    "    # 3. DEFINE STRUCTURED MESSAGES (Text first for Caching)\n",
    "    # Keeping the System Prompt as a separate object allows LM Studio to cache it.\n",
    "    # The 'Text' is now first to ensure it's part of the stable prefix, which basically means that the model's cache will be able to reload up to the excerpt_text before consider each target_symbol.\n",
    "    user_content = f\"Text:\\n{excerpt_text}\\n\\nTarget Symbol: {target_symbol}\\nOutput:\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_content}\n",
    "    ]\n",
    "    # 2. BUILD FLAT PROMPT (system + user)\n",
    "    # prompt = SYSTEM_PROMPT + \"\\n\\n\" + f\"Target: {target_symbol}\\nText: {excerpt_text}\\nOutput:\"\n",
    "\n",
    "    # 3. GENERATE (no .chat, use .respond)\n",
    "    try:\n",
    "        result = model.respond({\"messages\": messages}, config={\"temperature\": 0.1})\n",
    "        raw_text = str(result).strip()\n",
    "\n",
    "        # SEPARATE THOUGHTS FROM ANSWER\n",
    "        thoughts, clean_answer = separate_thoughts(raw_text)\n",
    "        \n",
    "        # You can log thoughts for debugging, but return the clean answer\n",
    "        if verbose and thoughts:\n",
    "            print(f\"\\n[Model Logic Trace]: {thoughts[:100]}...\")\n",
    "        if return_thoughts and thoughts:\n",
    "            return SummaryResponse(thoughts=thoughts, output=clean_answer)\n",
    "        else:\n",
    "            return clean_answer\n",
    "    except Exception as e:\n",
    "        print(f\"LLM Generation Error: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21e10f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models on lms may be loaded as follows:\n",
    "\n",
    "# Load methods\n",
    "# import lmstudio as lms\n",
    "# from lmstudio import LLM\n",
    "# from typing import TypedDict\n",
    "\n",
    "# Initialize Model; do one of the following:\n",
    "# model = lms.llm(\"google/gemma-3-27b\") # This loads a model that has been already been downloaded in lmstudio.\n",
    "# model = lms.llm() # Run this after loading a model on lmstduio.\n",
    "\n",
    "# target = r\"ht(\\mathfrak{p})\"\n",
    "# raw_text = r\"\"\"Let $A$ be a commutative ring... The height of a prime ideal $\\mathfrak{p}$, which we will denote by ht(\\mathfrak{p}), is defined to be the Krull dimension of the localization of $A$ at $\\mathfrak{p}$, that is, $ht(\\mathfrak{p}) := \\dim(A_\\mathfrak{p})$.\"\"\"\n",
    "\n",
    "# print(f\"Target: {target}\")\n",
    "# summary = generate_notation_summary(model, raw_text, target, return_thoughts=True)\n",
    "\n",
    "# if isinstance(summary, str):\n",
    "#     print(\"\\n--- Model Output ---\")\n",
    "#     print(summary)\n",
    "#     print(\"--------------------\")\n",
    "# else:\n",
    "#     print(\"\\n--- Model Output ---\")\n",
    "#     print(summary[\"output\"])\n",
    "#     print(\"--------------------\")\n",
    "#     print(\"\\n--- Model Thoughts ---\")\n",
    "#     print(summary[\"thoughts\"])\n",
    "#     print(\"--------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a5da7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Model Logic Trace]: First identify Gal(L/K) in text. Then summarize its role in context....\n",
      "Summary1: 'Gal(L/K) is the Galois group of the extension L/K, measuring symmetries of the field extension.'\n"
     ]
    }
   ],
   "source": [
    "#| exec\n",
    "from types import SimpleNamespace\n",
    "from typing import TypedDict\n",
    "\n",
    "class SummaryResponse(TypedDict):\n",
    "    thoughts: str\n",
    "    output: str\n",
    "\n",
    "class MockLLM:\n",
    "    def tokenize(self, text): \n",
    "        # Return LIST of token IDs (what real LLMs return)\n",
    "        return list(range(len(text) // 4 + 1))  # Mock token IDs\n",
    "    \n",
    "    def respond(self, messages, config=None):\n",
    "        return \"\"\"<think>First identify Gal(L/K) in text. Then summarize its role in context.</think>\n",
    "Gal(L/K) is the Galois group of the extension L/K, measuring symmetries of the field extension.\"\"\"\n",
    "\n",
    "mock_llm = MockLLM()\n",
    "NOTATION_SUMMARIZATION_SYSTEM_PROMPT = \"Summarize the mathematical role of the target symbol in the given text.\"\n",
    "\n",
    "# Now works!\n",
    "summary1 = generate_notation_summary(\n",
    "    mock_llm, \n",
    "    \"Let L/K be Galois. Gal(L/K) acts on roots.\", \n",
    "    \"Gal(L/K)\"\n",
    ")\n",
    "print(\"Summary1:\", repr(summary1))\n",
    "test_eq(len(mock_llm.tokenize(\"test\")), 2)  # len() works on list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5754f8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Model Logic Trace]: First identify Gal(L/K) in text. Then summarize its role in context....\n"
     ]
    }
   ],
   "source": [
    "#| exec\n",
    "# Example 2: Return thoughts\n",
    "response2 = generate_notation_summary(\n",
    "    mock_llm, \n",
    "    \"The étale cohomology computes Gal(L/K).\", \n",
    "    \"Gal(L/K)\",\n",
    "    return_thoughts=True\n",
    ")\n",
    "test_eq(response2[\"thoughts\"], \"First identify Gal(L/K) in text. Then summarize its role in context.\")\n",
    "test_eq(response2[\"output\"], \"Gal(L/K) is the Galois group of the extension L/K, measuring symmetries of the field extension.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6793ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Model Logic Trace]: First identify Gal(L/K) in text. Then summarize its role in context....\n",
      "Truncated: True\n"
     ]
    }
   ],
   "source": [
    "#| exec\n",
    "# Example 3: Truncation\n",
    "long_text = \"Mathematical text about Galois groups...\" * 200\n",
    "summary3 = generate_notation_summary(mock_llm, long_text, \"Gal(L/K)\", verbose=True)\n",
    "print(\"Truncated:\", len(summary3) > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc3a097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Model Logic Trace]: First identify Gal(L/K) in text. Then summarize its role in context....\n",
      "\n",
      "[Model Logic Trace]: First identify Gal(L/K) in text. Then summarize its role in context....\n",
      "\n",
      "[Model Logic Trace]: First identify Gal(L/K) in text. Then summarize its role in context....\n",
      "LLM Generation Error: FailingLLM.respond() got an unexpected keyword argument 'config'\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "from fastcore.test import *\n",
    "\n",
    "mock_llm_no_thoughts = MockLLM()\n",
    "mock_llm_no_thoughts.respond = lambda s,m,c: \"Direct answer\"\n",
    "mock_llm_no_thoughts.tokenize = lambda s,t: list(range(len(t)//4 + 1))\n",
    "\n",
    "# Tokenization works\n",
    "assert len(mock_llm.tokenize(\"test text\")) > 0\n",
    "assert isinstance(mock_llm.tokenize(\"test\"), list)\n",
    "\n",
    "# Function works\n",
    "result = generate_notation_summary(mock_llm, \"text\", \"symbol\")\n",
    "assert isinstance(result, str)\n",
    "assert len(result) > 0\n",
    "\n",
    "# Return types\n",
    "str_result = generate_notation_summary(mock_llm, \"text\", \"symbol\", return_thoughts=False)\n",
    "assert isinstance(str_result, str)\n",
    "\n",
    "dict_result = generate_notation_summary(mock_llm, \"text\", \"symbol\", return_thoughts=True)\n",
    "assert isinstance(dict_result, dict)\n",
    "assert \"thoughts\" in dict_result\n",
    "assert \"output\" in dict_result\n",
    "\n",
    "# Error handling\n",
    "class FailingLLM:\n",
    "    def tokenize(self, t): return []\n",
    "    def respond(self, m, c): raise ValueError(\"fail\")\n",
    "assert generate_notation_summary(FailingLLM(), \"text\", \"symbol\") == \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5815a66f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2e298f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
