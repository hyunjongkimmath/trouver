"""Functions for summarizing notations using a large language model."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/07_machine_learning_21.llm_notation_summarization.ipynb.

# %% auto 0
__all__ = ['NOTATION_SUMMARIZATION_SYSTEM_PROMPT', 'example_from_notation_note', 'notation_note_should_be_summarized',
           'separate_thoughts', 'SummaryResponse', 'generate_notation_summary']

# %% ../../nbs/07_machine_learning_21.llm_notation_summarization.ipynb 3
from os import PathLike
from typing import Optional, TypedDict
import re

import lmstudio as lms
from lmstudio import LLM

from ..obsidian.file import MarkdownFile, MarkdownLineEnum

from .notation_summarization import _summary_should_be_generated, _get_summary, get_latex_in_original_from_parsed_notation_note_data, single_input_for_notation_summarization, notation_summarization_data_from_note, _write_summary_to_notation_note, format_training_tokens, format_for_gemma_instruct


from ..personal_vault.note_processing import process_standard_information_note
from ..notation.parse import main_of_notation, parse_notation_note
from ..obsidian.vault import VaultNote

from ..obsidian.links import links_from_text

# %% ../../nbs/07_machine_learning_21.llm_notation_summarization.ipynb 5
# --- 1. SYSTEM PROMPT (TARGET + TEXT SPLIT) ---
NOTATION_SUMMARIZATION_SYSTEM_PROMPT = r"""
# Role
You are a strict, non-conversational mathematical compiler. Your task is to extract a rigorous definition summary from the provided text for a specific **Target Symbol**.

# Input Data
1.  **Text:** The raw mathematical excerpt containing the definition.
2.  **Target:** The specific notation to extract and define from the text above.

# Goal
Generate the prose continuation of a sentence starting with: "$SYMBOL$ [[SOURCE|denotes]]..."
**Start your output immediately with the noun phrase.** The output must be mathematically precise, grammatically correct prose where all mathematics in valid MathJax/LaTeX that is renderable in Obsidian.md markdown.

# Generation Rules

## 1. The "Identity Signature"
- **Priority:** Use the formal name if given (e.g., "the norm," "the sheaf of differentials").
- **Parent Context:** Immediately link the symbol to its primary parameters in the first sentence (e.g., "of a morphism $f$," "of an ideal $\mathfrak{a}$").

## 2. The Operational Definition
- Explain **how** it is constructed using the **exact abstraction level** of the text.
- **Justification:** Keep "because" clauses that explain well-definedness (e.g., "finite because it is full-rank").
- **Procedural Logic:** If the text lists steps (1, 2, 3), use a numbered list.
- **Formulas:** Include the defining equation.

## 3. Context Reconstruction ("Where" Clause) 
- **Recursive Unwinding:** Do not just list variables; **briefly define them**.   
- *Bad:* "...where $cl_X$ is the cycle class map."  
- *Good:* "...where $cl_X: CH^i(X) \to H^{2i}(X)$ is the cycle class map."
 - **Integration:** Use a "where..." clause immediately following the definition to define variables like $K, \mathcal{O}_K$, $X, Y$.

## 4. Structural Characterizations
- **New Paragraph:** Start a new paragraph for distinct properties or theorems.
- **Subject Focus:** Only include statements that describe the target symbol itself.
- **Negative Constraint:** Do not include definitions of *other* concepts (like "Catenary Ring") just because they mention the target symbol.

## 5. Constraints
- **Tone:** Clinical, precise. No "We defined," "Note that."
- **Safety:** ABSOLUTELY NO EMOJIS. NO MARKDOWN CODE BLOCKS.

## 6. LaTeX Standardization (MANDATORY)
- **Error Correction:** You must fix syntactic errors in the input. If the text has `\frac a b` (ambiguous) or `\alph` (typo), output correct standard LaTeX: `\frac{a}{b}`, `\alpha`.
- **Obsidian Format:**
  - Use `$` for inline math.
  - Use `$$` for block math/equations.
  - Use `$$\begin{align*} ... \end{align*}$$` for multi-line definitions.
  - NEVER use `\(` `\)` `\[` `\]`.
- **Notation:**
  - Convert plain text operators to commands: "Gal" -> `\operatorname{Gal}`, "Hom" -> `\operatorname{Hom}` (or use \mathrm or \mathbf, etc. as appropriate for the text).

## 7. Input Sanitization

    Text Cleaning: If the input text contains typos (e.g., "morphism off schemes", "defind as"), correct the spelling in your prose output.

    Variable Consistency: If the input text uses inconsistent notation for the same object (e.g., switching between $\epsilon$ and $\varepsilon$ randomly), standardize to the most common or standard usage in the definition.

    Noise Removal: Ignore filler words like "clearly," "obviously," or conversational asides found in the source text.
---

# Example 1: Constructive Object
**Text:**
Let $f: X \to Y$ be a morphism of schemes... The sheaf of relative differentials, denoted $\Omega_{X/Y}$, is then defined to be the pullback of this conormal sheaf... That is, $\Omega_{X/Y} := \Delta^*(\mathcal{I}/\mathcal{I}^2)$.
**Target:** \Omega_{X/Y}
**Output:**
the sheaf of relative differentials of a morphism $f: X \to Y$ of schemes. It is defined as the pullback $\Omega_{X/Y} := \Delta^*(\mathcal{I}/\mathcal{I}^2)$, where $\mathcal{I}$ is the ideal sheaf of the diagonal immersion $\Delta: X \to X \times_Y X$. Since the conormal sheaf $\mathcal{I}/\mathcal{I}^2$ is a sheaf on the diagonal $\Delta(X)$ (viewed as a sheaf on $X$), the result is a sheaf on $X$.

An important property is that for affine open subschemes $U \subseteq X$ and $V \subseteq Y$ with $f(U) \subseteq V$, the sections $\Omega_{X/Y}(U)$ are isomorphic to the module of relative differentials $\Omega_{A/R}$.

# Example 2: Property/Value
**Text:**
Let $K$ be a number field... We define the norm of an ideal $\mathfrak{a}$, denoted $N(\mathfrak{a})$, to be the cardinality of the quotient ring $\mathcal{O}_K / \mathfrak{a}$. Since $\mathfrak{a}$ is a full-rank sublattice of $\mathcal{O}_K$, this quotient ring is always finite.
**Target:** N(\mathfrak{a})
**Output:**
the norm of a non-zero ideal $\mathfrak{a}$ in the ring of integers $\mathcal{O}_K$ of a number field $K$. It is defined as the cardinality of the quotient ring $N(\mathfrak{a}) := |\mathcal{O}_K / \mathfrak{a}|$. This quotient is always finite because $\mathfrak{a}$ is a full-rank sublattice of $\mathcal{O}_K$.

The norm is a completely multiplicative function, meaning $N(\mathfrak{a}\mathfrak{b}) = N(\mathfrak{a})N(\mathfrak{b})$ for any non-zero ideals $\mathfrak{a}, \mathfrak{b}$.

# Example 3: Procedural Definition
**Text:**
Thus if $D \in \operatorname{Div}(V)$ is a divisor and we want to choose a particular height function $h_{V, D}$, we need to make the following choices:
[1] Choose very ample divisors $D_{1}$ and $D_{2}$ with $D=D_{1}-D_{2}$.
...
**Target:** h_{V,D}
**Output:**
a particular height function for a divisor $D$ on a variety $V$. It is defined by the following construction:
1. Choose very ample divisors $D_{1}$ and $D_{2}$ such that $D=D_{1}-D_{2}$.
2. Choose embeddings $\phi_{1}: V \rightarrow \mathbb{P}^{n}$ and $\phi_{2}: V \rightarrow \mathbb{P}^{m}$ corresponding respectively to $D_{1}$ and $D_{2}$.
3. Set $h_{V, D}(P)=h\left(\phi_{1}(P)\right)-h\left(\phi_{2}(P)\right)$.

# Example 4: Inconsistency Standardization
**Text:**
The set of morphisms between schemes X and Y is usually writen Hom(X,Y). We say that a morphism $f \in \operatorname{Hom}(X, Y)$ is separated if the diagonal is a closed immersion.
**Target:** \operatorname{Hom}(X,Y)
**Output:**
the set of morphisms between schemes $X$ and $Y$. 

"""



# %% ../../nbs/07_machine_learning_21.llm_notation_summarization.ipynb 6
def example_from_notation_note(
        notation_note: VaultNote
        ) -> dict[str, str]: # Keys include 'processed_main_note_content' and 'latex_in_original'
    """
    Helper to parse `notation_note` and gather data for summarization.
    
    This function extracts the LaTeX used in the original main note and 
    retrieves the processed content of that main note.
    """
    parsed = parse_notation_note(notation_note)

    # Access the main note (the one where the notation is defined)
    main_note = VaultNote(
        vault=notation_note.vault, name=parsed.name_of_main_note)
    
    # Process the main note's content to remove metadata/formatting
    main_note_mf = MarkdownFile.from_vault_note(main_note)
    main_note_content = str(process_standard_information_note(main_note_mf, notation_note.vault))

    # Identify the specific LaTeX string as it appeared in the source
    latex_in_original = get_latex_in_original_from_parsed_notation_note_data(
            parsed.yaml_frontmatter_meta, parsed.notation_str)
    
    # Extract existing summary data
    summary_data = notation_summarization_data_from_note(
        notation_note, notation_note.vault, check_for_actual_summarization=False)
    
    return summary_data

# %% ../../nbs/07_machine_learning_21.llm_notation_summarization.ipynb 9
# def notation_note_should_be_summarized(
#         notation_note: VaultNote,
#         vault: PathLike,
#         main_note: Optional[VaultNote] = None, # The main note from which the notation comes from. If this is `None`, then the `main_note` is obtained via the `main_of_notation` function.
#         overwrite_previous_autogenerated_summary: bool = False, # If `True`, overwrite previously autogenerated summaries
#         latex_in_original_comes_first: bool = True # This is a parameter to pass to calls to the `single_input_for_notation_summarization` function. If `True`, the `latex_in_original` piece appears before the `main_note_content`. While the default value of `True` is recommended, passing `False` to this parameter may be necessary to use the older version of the summarization model in the repo [`notation_summarizations_model`](https://huggingface.co/hyunjongkimmath/notation_summarizations_model).
#     ) -> bool:
#     r"""
#     Return `True` if notation note has no summary or an autogenerated summary.

#     Helper to tell
#     """
#     metadata, notation_str, main_note_name,\
#         notation_note_content_mf, _\
#         = parse_notation_note(notation_note, vault)
#     summary_should_be_generated, main_mf = _summary_should_be_generated(
#         main_note, main_note_name, vault, notation_note,
#         overwrite_previous_autogenerated_summary,
#         metadata, notation_note_content_mf)
#     return summary_should_be_generated

def notation_note_should_be_summarized(
        notation_note: VaultNote,
        vault: PathLike,
        main_note: Optional[VaultNote] = None, # The main note from which the notation comes from. If this is `None`, then the `main_note` is obtained via the `main_of_notation` function.
        overwrite_previous_autogenerated_summary: bool = False, # If `True`, overwrite previously autogenerated summaries
        latex_in_original_comes_first: bool = True # This is a parameter to pass to calls to the `single_input_for_notation_summarization` function. If `True`, the `latex_in_original` piece appears before the `main_note_content`. While the default value of `True` is recommended, passing `False` to this parameter may be necessary to use the older version of the summarization model in the repo [`notation_summarizations_model`](https://huggingface.co/hyunjongkimmath/notation_summarizations_model).
    ) -> bool:
    r"""
    Return `True` if a notation note has no summary or contains an autogenerated summary that should be updated.

    This helper determines if the note is a candidate for the summarization pipeline based on:
    1. The presence of the `_auto/notation_summary` tag (if `overwrite_previous_autogenerated_summary` is True).
    2. Whether the note currently lacks content beyond the "denotes" link.
    3. Whether the main reference note actually exists and contains content.
    """
    # parse_notation_note retrieves metadata, the notation string, and the main note's name
    metadata, notation_str, main_note_name,\
        notation_note_content_mf, _\
        = parse_notation_note(notation_note, vault)
        
    # _summary_should_be_generated performs the logic of checking if the main note exists
    # and if the notation note is already "sufficiently summarized" or tagged as auto-generated.
    summary_should_be_generated, _ = _summary_should_be_generated(
        main_note, main_note_name, vault, notation_note,
        overwrite_previous_autogenerated_summary,
        metadata, notation_note_content_mf)
        
    return summary_should_be_generated

# %% ../../nbs/07_machine_learning_21.llm_notation_summarization.ipynb 12
def separate_thoughts(raw_content: str):
    """
    Separates model 'reasoning' from the actual answer.
    Handles <think>, <thought>, and [THOUGHT] tags.
    """
    # 1. Define common patterns for thinking blocks
    # This regex looks for <think>...</think> or  (case insensitive)
    tag_pattern = r"<(think|thought)>([\s\S]*?)<\/\1>"
    
    match = re.search(tag_pattern, raw_content, re.IGNORECASE)
    
    if match:
        thoughts = match.group(2).strip()
        # Remove the thinking block from the main content
        answer = re.sub(tag_pattern, "", raw_content, flags=re.IGNORECASE).strip()
        return thoughts, answer
    
    # 2. Fallback for models that don't use tags but use a header
    if "THOUGHTS:" in raw_content.upper():
        parts = re.split(r"THOUGHTS:", raw_content, flags=re.IGNORECASE)
        # Assuming format: THOUGHTS: [logic] ANSWER: [result]
        if "ANSWER:" in parts[1].upper():
            sub_parts = re.split(r"ANSWER:", parts[1], flags=re.IGNORECASE)
            return sub_parts[0].strip(), sub_parts[1].strip()
            
    # 3. If no markers found, return everything as the answer
    return None, raw_content.strip()

# %% ../../nbs/07_machine_learning_21.llm_notation_summarization.ipynb 17
# --- 2. CORE FUNCTIONS ---

class SummaryResponse(TypedDict):
    thoughts: str
    output: str

def generate_notation_summary(
        model: LLM,
        excerpt_text: str,
        target_symbol: str,
        max_context: int = 4096,
        verbose: bool = True,
        return_thoughts: bool = False,
        system_prompt: str = NOTATION_SUMMARIZATION_SYSTEM_PROMPT,
        ) -> str | SummaryResponse:
    # 1. PRE-CALCULATE TOKENS FOR TRUNCATION
    # Use Text -> Target order to favor caching
    sys_tokens = len(model.tokenize(NOTATION_SUMMARIZATION_SYSTEM_PROMPT))
    target_overhead = len(model.tokenize(f"\n\nTarget Symbol: {target_symbol}\nOutput:"))
    safety_margin = 500 
    
    available_for_text = max_context - sys_tokens - safety_margin - target_overhead
    # excerpt_tokens = model.tokenize(excerpt_text)


    # 2. SMART TRUNCATION (Using .decode instead of .detokenize)
    # 2. SMART TRUNCATION
    estimated_char_limit = available_for_text * 3
    
    if len(excerpt_text) > estimated_char_limit:
        # Slice the string directly
        excerpt_text = excerpt_text[:estimated_char_limit]
        
        if verbose:
            print(f"Warning: Excerpt truncated to {len(excerpt_text)} characters (approx. {available_for_text} tokens).")


    # 3. DEFINE STRUCTURED MESSAGES (Text first for Caching)
    # Keeping the System Prompt as a separate object allows LM Studio to cache it.
    # The 'Text' is now first to ensure it's part of the stable prefix, which basically means that the model's cache will be able to reload up to the excerpt_text before consider each target_symbol.
    user_content = f"Text:\n{excerpt_text}\n\nTarget Symbol: {target_symbol}\nOutput:"
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_content}
    ]
    # 2. BUILD FLAT PROMPT (system + user)
    # prompt = SYSTEM_PROMPT + "\n\n" + f"Target: {target_symbol}\nText: {excerpt_text}\nOutput:"

    # 3. GENERATE (no .chat, use .respond)
    try:
        result = model.respond({"messages": messages}, config={"temperature": 0.1})
        raw_text = str(result).strip()

        # SEPARATE THOUGHTS FROM ANSWER
        thoughts, clean_answer = separate_thoughts(raw_text)
        
        # You can log thoughts for debugging, but return the clean answer
        if verbose and thoughts:
            print(f"\n[Model Logic Trace]: {thoughts[:100]}...")
        if return_thoughts and thoughts:
            return SummaryResponse(thoughts=thoughts, output=clean_answer)
        else:
            return clean_answer
    except Exception as e:
        print(f"LLM Generation Error: {e}")
        return ""

